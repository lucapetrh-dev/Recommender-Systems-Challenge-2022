{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "import matplotlib.pyplot as pyplot\n",
    "\n",
    "from Evaluation.Evaluator import EvaluatorHoldout\n",
    "from Data_manager.split_functions.split_train_validation_random_holdout import split_train_in_two_percentage_global_sample\n",
    "from Utils.DataReader import load_urm, load_icm, load_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 914 (2.20 %) of 41629 users have no sampled items\n",
      "Warning: 1506 (3.62 %) of 41629 users have no sampled items\n",
      "EvaluatorHoldout: Ignoring 1506 ( 3.6%) Users that have less than 1 test interactions\n",
      "EvaluatorHoldout: Ignoring 914 ( 2.2%) Users that have less than 1 test interactions\n"
     ]
    }
   ],
   "source": [
    "URM_all = load_urm()\n",
    "\n",
    "URM_train, URM_test = split_train_in_two_percentage_global_sample(URM_all, train_percentage = 0.85)\n",
    "URM_train, URM_validation = split_train_in_two_percentage_global_sample(URM_train, train_percentage = 0.85)\n",
    "\n",
    "evaluator_validation = EvaluatorHoldout(URM_validation, cutoff_list=[10])\n",
    "evaluator_test = EvaluatorHoldout(URM_test, cutoff_list=[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIMElasticNetRecommender: Processed 1476 ( 6.0%) in 5.00 min. Items per second: 4.91\n"
     ]
    }
   ],
   "source": [
    "from Recommenders.SLIM.SLIMElasticNetRecommender import SLIMElasticNetRecommender\n",
    "\n",
    "recommender_SLIMElasticNet = SLIMElasticNetRecommender(URM_train)\n",
    "recommender_SLIMElasticNet.fit(topK=405, l1_ratio=0.0010299956370568744, alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_compile_all_cython: Found 10 Cython files in 4 folders...\n",
      "run_compile_all_cython: All files will be compiled using your current python environment: '/opt/miniconda3/envs/tensorflow/bin/python'\n",
      "Compiling [1/10]: MatrixFactorizationImpressions_Cython_Epoch.pyx... \n",
      "In file included from MatrixFactorizationImpressions_Cython_Epoch.c:746:\n",
      "In file included from /opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h:5:\n",
      "In file included from /opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h:12:\n",
      "In file included from /opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h:1948:\n",
      "\u001B[1m/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2: \u001B[0m\u001B[0;1;35mwarning: \u001B[0m\u001B[1m\"Using deprecated NumPy API, disable it with \"          \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-W#warnings]\u001B[0m\n",
      "#warning \"Using deprecated NumPy API, disable it with \" \\\n",
      "\u001B[0;1;32m ^\n",
      "\u001B[0m\u001B[1mMatrixFactorizationImpressions_Cython_Epoch.c:32418:21: \u001B[0m\u001B[0;1;35mwarning: \u001B[0m\u001B[1mfallthrough annotation in unreachable code [-Wunreachable-code-fallthrough]\u001B[0m\n",
      "                    CYTHON_FALLTHROUGH;\n",
      "\u001B[0;1;32m                    ^\n",
      "\u001B[0m\u001B[1mMatrixFactorizationImpressions_Cython_Epoch.c:341:34: \u001B[0m\u001B[0;1;30mnote: \u001B[0mexpanded from macro 'CYTHON_FALLTHROUGH'\u001B[0m\n",
      "      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))\n",
      "\u001B[0;1;32m                                 ^\n",
      "\u001B[0m\u001B[1mMatrixFactorizationImpressions_Cython_Epoch.c:32429:21: \u001B[0m\u001B[0;1;35mwarning: \u001B[0m\u001B[1mfallthrough annotation in unreachable code [-Wunreachable-code-fallthrough]\u001B[0m\n",
      "                    CYTHON_FALLTHROUGH;\n",
      "\u001B[0;1;32m                    ^\n",
      "\u001B[0m\u001B[1mMatrixFactorizationImpressions_Cython_Epoch.c:341:34: \u001B[0m\u001B[0;1;30mnote: \u001B[0mexpanded from macro 'CYTHON_FALLTHROUGH'\u001B[0m\n",
      "      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))\n",
      "\u001B[0;1;32m                                 ^\n",
      "\u001B[0m3 warnings generated.\n",
      "/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /Users/ema/Downloads/Recommender-Systems-Challenge-2022-main/Recommenders/MatrixFactorization/Cython/MatrixFactorizationImpressions_Cython_Epoch.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "Compiling [1/10]: MatrixFactorizationImpressions_Cython_Epoch.pyx... PASS\n",
      "\n",
      "Compiling [2/10]: MatrixFactorization_Cython_Epoch.pyx... \n",
      "In file included from MatrixFactorization_Cython_Epoch.c:746:\n",
      "In file included from /opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h:5:\n",
      "In file included from /opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h:12:\n",
      "In file included from /opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h:1948:\n",
      "\u001B[1m/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2: \u001B[0m\u001B[0;1;35mwarning: \u001B[0m\u001B[1m\"Using deprecated NumPy API, disable it with \"          \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-W#warnings]\u001B[0m\n",
      "#warning \"Using deprecated NumPy API, disable it with \" \\\n",
      "\u001B[0;1;32m ^\n",
      "\u001B[0m\u001B[1mMatrixFactorization_Cython_Epoch.c:32229:21: \u001B[0m\u001B[0;1;35mwarning: \u001B[0m\u001B[1mfallthrough annotation in unreachable code [-Wunreachable-code-fallthrough]\u001B[0m\n",
      "                    CYTHON_FALLTHROUGH;\n",
      "\u001B[0;1;32m                    ^\n",
      "\u001B[0m\u001B[1mMatrixFactorization_Cython_Epoch.c:341:34: \u001B[0m\u001B[0;1;30mnote: \u001B[0mexpanded from macro 'CYTHON_FALLTHROUGH'\u001B[0m\n",
      "      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))\n",
      "\u001B[0;1;32m                                 ^\n",
      "\u001B[0m\u001B[1mMatrixFactorization_Cython_Epoch.c:32240:21: \u001B[0m\u001B[0;1;35mwarning: \u001B[0m\u001B[1mfallthrough annotation in unreachable code [-Wunreachable-code-fallthrough]\u001B[0m\n",
      "                    CYTHON_FALLTHROUGH;\n",
      "\u001B[0;1;32m                    ^\n",
      "\u001B[0m\u001B[1mMatrixFactorization_Cython_Epoch.c:341:34: \u001B[0m\u001B[0;1;30mnote: \u001B[0mexpanded from macro 'CYTHON_FALLTHROUGH'\u001B[0m\n",
      "      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))\n",
      "\u001B[0;1;32m                                 ^\n",
      "\u001B[0m3 warnings generated.\n",
      "/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /Users/ema/Downloads/Recommender-Systems-Challenge-2022-main/Recommenders/MatrixFactorization/Cython/MatrixFactorization_Cython_Epoch.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "Compiling [2/10]: MatrixFactorization_Cython_Epoch.pyx... PASS\n",
      "\n",
      "Compiling [3/10]: Compute_Similarity_Cython.pyx... \n",
      "In file included from Compute_Similarity_Cython.c:746:\n",
      "In file included from /opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h:5:\n",
      "In file included from /opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h:12:\n",
      "In file included from /opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h:1948:\n",
      "\u001B[1m/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2: \u001B[0m\u001B[0;1;35mwarning: \u001B[0m\u001B[1m\"Using deprecated NumPy API, disable it with \"          \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-W#warnings]\u001B[0m\n",
      "#warning \"Using deprecated NumPy API, disable it with \" \\\n",
      "\u001B[0;1;32m ^\n",
      "\u001B[0m\u001B[1mCompute_Similarity_Cython.c:28901:21: \u001B[0m\u001B[0;1;35mwarning: \u001B[0m\u001B[1mfallthrough annotation in unreachable code [-Wunreachable-code-fallthrough]\u001B[0m\n",
      "                    CYTHON_FALLTHROUGH;\n",
      "\u001B[0;1;32m                    ^\n",
      "\u001B[0m\u001B[1mCompute_Similarity_Cython.c:341:34: \u001B[0m\u001B[0;1;30mnote: \u001B[0mexpanded from macro 'CYTHON_FALLTHROUGH'\u001B[0m\n",
      "      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))\n",
      "\u001B[0;1;32m                                 ^\n",
      "\u001B[0m\u001B[1mCompute_Similarity_Cython.c:28912:21: \u001B[0m\u001B[0;1;35mwarning: \u001B[0m\u001B[1mfallthrough annotation in unreachable code [-Wunreachable-code-fallthrough]\u001B[0m\n",
      "                    CYTHON_FALLTHROUGH;\n",
      "\u001B[0;1;32m                    ^\n",
      "\u001B[0m\u001B[1mCompute_Similarity_Cython.c:341:34: \u001B[0m\u001B[0;1;30mnote: \u001B[0mexpanded from macro 'CYTHON_FALLTHROUGH'\u001B[0m\n",
      "      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))\n",
      "\u001B[0;1;32m                                 ^\n",
      "\u001B[0m3 warnings generated.\n",
      "/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /Users/ema/Downloads/Recommender-Systems-Challenge-2022-main/Recommenders/Similarity/Cython/Compute_Similarity_Cython.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "Compiling [3/10]: Compute_Similarity_Cython.pyx... PASS\n",
      "\n",
      "Compiling [4/10]: Sparse_Matrix_Tree_CSR.pyx... \n",
      "/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /Users/ema/Downloads/Recommender-Systems-Challenge-2022-main/Recommenders/SLIM/Cython/Sparse_Matrix_Tree_CSR.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:132:34: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:132:66: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:343:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:343:52: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:442:69: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:577:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:577:42: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:578:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: Sparse_Matrix_Tree_CSR.pyx:578:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling [4/10]: Sparse_Matrix_Tree_CSR.pyx... PASS\n",
      "\n",
      "Compiling [5/10]: Triangular_Matrix.pyx... \n",
      "In file included from Triangular_Matrix.c:746:\n",
      "In file included from /opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h:5:\n",
      "In file included from /opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h:12:\n",
      "In file included from /opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h:1948:\n",
      "\u001B[1m/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2: \u001B[0m\u001B[0;1;35mwarning: \u001B[0m\u001B[1m\"Using deprecated NumPy API, disable it with \"          \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-W#warnings]\u001B[0m\n",
      "#warning \"Using deprecated NumPy API, disable it with \" \\\n",
      "\u001B[0;1;32m ^\n",
      "\u001B[0m1 warning generated.\n",
      "/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /Users/ema/Downloads/Recommender-Systems-Challenge-2022-main/Recommenders/SLIM/Cython/Triangular_Matrix.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "Compiling [5/10]: Triangular_Matrix.pyx... PASS\n",
      "\n",
      "Compiling [6/10]: SLIM_BPR_Cython_Epoch.pyx... \n",
      "In file included from SLIM_BPR_Cython_Epoch.c:746:\n",
      "In file included from /opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h:5:\n",
      "In file included from /opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h:12:\n",
      "In file included from /opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h:1948:\n",
      "\u001B[1m/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2: \u001B[0m\u001B[0;1;35mwarning: \u001B[0m\u001B[1m\"Using deprecated NumPy API, disable it with \"          \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-W#warnings]\u001B[0m\n",
      "#warning \"Using deprecated NumPy API, disable it with \" \\\n",
      "\u001B[0;1;32m ^\n",
      "\u001B[0m\u001B[1mSLIM_BPR_Cython_Epoch.c:33996:21: \u001B[0m\u001B[0;1;35mwarning: \u001B[0m\u001B[1mfallthrough annotation in unreachable code [-Wunreachable-code-fallthrough]\u001B[0m\n",
      "                    CYTHON_FALLTHROUGH;\n",
      "\u001B[0;1;32m                    ^\n",
      "\u001B[0m\u001B[1mSLIM_BPR_Cython_Epoch.c:341:34: \u001B[0m\u001B[0;1;30mnote: \u001B[0mexpanded from macro 'CYTHON_FALLTHROUGH'\u001B[0m\n",
      "      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))\n",
      "\u001B[0;1;32m                                 ^\n",
      "\u001B[0m\u001B[1mSLIM_BPR_Cython_Epoch.c:34007:21: \u001B[0m\u001B[0;1;35mwarning: \u001B[0m\u001B[1mfallthrough annotation in unreachable code [-Wunreachable-code-fallthrough]\u001B[0m\n",
      "                    CYTHON_FALLTHROUGH;\n",
      "\u001B[0;1;32m                    ^\n",
      "\u001B[0m\u001B[1mSLIM_BPR_Cython_Epoch.c:341:34: \u001B[0m\u001B[0;1;30mnote: \u001B[0mexpanded from macro 'CYTHON_FALLTHROUGH'\u001B[0m\n",
      "      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))\n",
      "\u001B[0;1;32m                                 ^\n",
      "\u001B[0m3 warnings generated.\n",
      "/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /Users/ema/Downloads/Recommender-Systems-Challenge-2022-main/Recommenders/SLIM/Cython/SLIM_BPR_Cython_Epoch.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:633:34: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:633:66: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:818:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:818:52: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:917:69: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1052:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1052:42: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1053:35: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "warning: SLIM_BPR_Cython_Epoch.pyx:1053:53: Non-trivial type declarators in shared declaration (e.g. mix of pointers and values). Each pointer declaration should be on its own line.\n",
      "Compiling [6/10]: SLIM_BPR_Cython_Epoch.pyx... PASS\n",
      "\n",
      "Compiling [7/10]: HP3_Similarity_Cython_SGD.pyx... \n",
      "In file included from HP3_Similarity_Cython_SGD.c:746:\n",
      "In file included from /opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h:5:\n",
      "In file included from /opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h:12:\n",
      "In file included from /opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h:1948:\n",
      "\u001B[1m/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2: \u001B[0m\u001B[0;1;35mwarning: \u001B[0m\u001B[1m\"Using deprecated NumPy API, disable it with \"          \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-W#warnings]\u001B[0m\n",
      "#warning \"Using deprecated NumPy API, disable it with \" \\\n",
      "\u001B[0;1;32m ^\n",
      "\u001B[0m\u001B[1mHP3_Similarity_Cython_SGD.c:28802:21: \u001B[0m\u001B[0;1;35mwarning: \u001B[0m\u001B[1mfallthrough annotation in unreachable code [-Wunreachable-code-fallthrough]\u001B[0m\n",
      "                    CYTHON_FALLTHROUGH;\n",
      "\u001B[0;1;32m                    ^\n",
      "\u001B[0m\u001B[1mHP3_Similarity_Cython_SGD.c:341:34: \u001B[0m\u001B[0;1;30mnote: \u001B[0mexpanded from macro 'CYTHON_FALLTHROUGH'\u001B[0m\n",
      "      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))\n",
      "\u001B[0;1;32m                                 ^\n",
      "\u001B[0m\u001B[1mHP3_Similarity_Cython_SGD.c:28813:21: \u001B[0m\u001B[0;1;35mwarning: \u001B[0m\u001B[1mfallthrough annotation in unreachable code [-Wunreachable-code-fallthrough]\u001B[0m\n",
      "                    CYTHON_FALLTHROUGH;\n",
      "\u001B[0;1;32m                    ^\n",
      "\u001B[0m\u001B[1mHP3_Similarity_Cython_SGD.c:341:34: \u001B[0m\u001B[0;1;30mnote: \u001B[0mexpanded from macro 'CYTHON_FALLTHROUGH'\u001B[0m\n",
      "      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))\n",
      "\u001B[0;1;32m                                 ^\n",
      "\u001B[0m3 warnings generated.\n",
      "/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /Users/ema/Downloads/Recommender-Systems-Challenge-2022-main/Recommenders/FeatureWeighting/Cython/HP3_Similarity_Cython_SGD.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "warning: HP3_Similarity_Cython_SGD.pyx:113:40: Index should be typed for more efficient access\n",
      "Compiling [7/10]: HP3_Similarity_Cython_SGD.pyx... PASS\n",
      "\n",
      "Compiling [8/10]: CFW_D_Similarity_Cython_SGD.pyx... \n",
      "In file included from CFW_D_Similarity_Cython_SGD.c:746:\n",
      "In file included from /opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h:5:\n",
      "In file included from /opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h:12:\n",
      "In file included from /opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h:1948:\n",
      "\u001B[1m/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2: \u001B[0m\u001B[0;1;35mwarning: \u001B[0m\u001B[1m\"Using deprecated NumPy API, disable it with \"          \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-W#warnings]\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#warning \"Using deprecated NumPy API, disable it with \" \\\n",
      "\u001B[0;1;32m ^\n",
      "\u001B[0m\u001B[1mCFW_D_Similarity_Cython_SGD.c:28563:21: \u001B[0m\u001B[0;1;35mwarning: \u001B[0m\u001B[1mfallthrough annotation in unreachable code [-Wunreachable-code-fallthrough]\u001B[0m\n",
      "                    CYTHON_FALLTHROUGH;\n",
      "\u001B[0;1;32m                    ^\n",
      "\u001B[0m\u001B[1mCFW_D_Similarity_Cython_SGD.c:341:34: \u001B[0m\u001B[0;1;30mnote: \u001B[0mexpanded from macro 'CYTHON_FALLTHROUGH'\u001B[0m\n",
      "      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))\n",
      "\u001B[0;1;32m                                 ^\n",
      "\u001B[0m\u001B[1mCFW_D_Similarity_Cython_SGD.c:28574:21: \u001B[0m\u001B[0;1;35mwarning: \u001B[0m\u001B[1mfallthrough annotation in unreachable code [-Wunreachable-code-fallthrough]\u001B[0m\n",
      "                    CYTHON_FALLTHROUGH;\n",
      "\u001B[0;1;32m                    ^\n",
      "\u001B[0m\u001B[1mCFW_D_Similarity_Cython_SGD.c:341:34: \u001B[0m\u001B[0;1;30mnote: \u001B[0mexpanded from macro 'CYTHON_FALLTHROUGH'\u001B[0m\n",
      "      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))\n",
      "\u001B[0;1;32m                                 ^\n",
      "\u001B[0m3 warnings generated.\n",
      "/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /Users/ema/Downloads/Recommender-Systems-Challenge-2022-main/Recommenders/FeatureWeighting/Cython/CFW_D_Similarity_Cython_SGD.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "Compiling [8/10]: CFW_D_Similarity_Cython_SGD.pyx... PASS\n",
      "\n",
      "Compiling [9/10]: FBSM_Rating_Cython_SGD.pyx... \n",
      "In file included from FBSM_Rating_Cython_SGD.c:746:\n",
      "In file included from /opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h:5:\n",
      "In file included from /opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h:12:\n",
      "In file included from /opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h:1948:\n",
      "\u001B[1m/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2: \u001B[0m\u001B[0;1;35mwarning: \u001B[0m\u001B[1m\"Using deprecated NumPy API, disable it with \"          \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-W#warnings]\u001B[0m\n",
      "#warning \"Using deprecated NumPy API, disable it with \" \\\n",
      "\u001B[0;1;32m ^\n",
      "\u001B[0m\u001B[1mFBSM_Rating_Cython_SGD.c:31139:21: \u001B[0m\u001B[0;1;35mwarning: \u001B[0m\u001B[1mfallthrough annotation in unreachable code [-Wunreachable-code-fallthrough]\u001B[0m\n",
      "                    CYTHON_FALLTHROUGH;\n",
      "\u001B[0;1;32m                    ^\n",
      "\u001B[0m\u001B[1mFBSM_Rating_Cython_SGD.c:341:34: \u001B[0m\u001B[0;1;30mnote: \u001B[0mexpanded from macro 'CYTHON_FALLTHROUGH'\u001B[0m\n",
      "      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))\n",
      "\u001B[0;1;32m                                 ^\n",
      "\u001B[0m\u001B[1mFBSM_Rating_Cython_SGD.c:31150:21: \u001B[0m\u001B[0;1;35mwarning: \u001B[0m\u001B[1mfallthrough annotation in unreachable code [-Wunreachable-code-fallthrough]\u001B[0m\n",
      "                    CYTHON_FALLTHROUGH;\n",
      "\u001B[0;1;32m                    ^\n",
      "\u001B[0m\u001B[1mFBSM_Rating_Cython_SGD.c:341:34: \u001B[0m\u001B[0;1;30mnote: \u001B[0mexpanded from macro 'CYTHON_FALLTHROUGH'\u001B[0m\n",
      "      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))\n",
      "\u001B[0;1;32m                                 ^\n",
      "\u001B[0m3 warnings generated.\n",
      "/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /Users/ema/Downloads/Recommender-Systems-Challenge-2022-main/Recommenders/FeatureWeighting/Cython/FBSM_Rating_Cython_SGD.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "Compiling [9/10]: FBSM_Rating_Cython_SGD.pyx... PASS\n",
      "\n",
      "Compiling [10/10]: CFW_DVV_Similarity_Cython_SGD.pyx... \n",
      "In file included from CFW_DVV_Similarity_Cython_SGD.c:746:\n",
      "In file included from /opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/arrayobject.h:5:\n",
      "In file included from /opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/ndarrayobject.h:12:\n",
      "In file included from /opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/ndarraytypes.h:1948:\n",
      "\u001B[1m/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2: \u001B[0m\u001B[0;1;35mwarning: \u001B[0m\u001B[1m\"Using deprecated NumPy API, disable it with \"          \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-W#warnings]\u001B[0m\n",
      "#warning \"Using deprecated NumPy API, disable it with \" \\\n",
      "\u001B[0;1;32m ^\n",
      "\u001B[0m\u001B[1mCFW_DVV_Similarity_Cython_SGD.c:35093:21: \u001B[0m\u001B[0;1;35mwarning: \u001B[0m\u001B[1mfallthrough annotation in unreachable code [-Wunreachable-code-fallthrough]\u001B[0m\n",
      "                    CYTHON_FALLTHROUGH;\n",
      "\u001B[0;1;32m                    ^\n",
      "\u001B[0m\u001B[1mCFW_DVV_Similarity_Cython_SGD.c:341:34: \u001B[0m\u001B[0;1;30mnote: \u001B[0mexpanded from macro 'CYTHON_FALLTHROUGH'\u001B[0m\n",
      "      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))\n",
      "\u001B[0;1;32m                                 ^\n",
      "\u001B[0m\u001B[1mCFW_DVV_Similarity_Cython_SGD.c:35104:21: \u001B[0m\u001B[0;1;35mwarning: \u001B[0m\u001B[1mfallthrough annotation in unreachable code [-Wunreachable-code-fallthrough]\u001B[0m\n",
      "                    CYTHON_FALLTHROUGH;\n",
      "\u001B[0;1;32m                    ^\n",
      "\u001B[0m\u001B[1mCFW_DVV_Similarity_Cython_SGD.c:341:34: \u001B[0m\u001B[0;1;30mnote: \u001B[0mexpanded from macro 'CYTHON_FALLTHROUGH'\u001B[0m\n",
      "      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))\n",
      "\u001B[0;1;32m                                 ^\n",
      "\u001B[0m3 warnings generated.\n",
      "/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /Users/ema/Downloads/Recommender-Systems-Challenge-2022-main/Recommenders/FeatureWeighting/Cython/CFW_DVV_Similarity_Cython_SGD.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "Compiling [10/10]: CFW_DVV_Similarity_Cython_SGD.pyx... PASS\n",
      "\n",
      "run_compile_all_cython: Compilation finished. SUCCESS.\n",
      "Compilation log can be found here: './result_experiments/run_compile_all_cython.txt'\n"
     ]
    }
   ],
   "source": [
    "import pyximport\n",
    "pyximport.install()\n",
    "!python run_compile_all_cython.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to read memory status: list index out of range\n",
      "SLIM_BPR_Recommender: Automatic selection of fastest train mode. Unable to get current RAM status, you may be using a non-Linux operating system. Using dense matrix.\n",
      "Processed 41629 (100.0%) in 1.06 sec. BPR loss is 6.30E-02. Sample per second: 39239\n",
      "SLIM_BPR_Recommender: Epoch 1 of 465. Elapsed time 0.19 sec\n",
      "Processed 41629 (100.0%) in 0.25 sec. BPR loss is 2.80E-01. Sample per second: 169766\n",
      "SLIM_BPR_Recommender: Epoch 2 of 465. Elapsed time 0.37 sec\n",
      "Processed 41629 (100.0%) in 0.42 sec. BPR loss is 5.03E-01. Sample per second: 98464\n",
      "SLIM_BPR_Recommender: Epoch 3 of 465. Elapsed time 0.55 sec\n",
      "Processed 41629 (100.0%) in 0.63 sec. BPR loss is 7.45E-01. Sample per second: 66485\n",
      "SLIM_BPR_Recommender: Epoch 4 of 465. Elapsed time 0.75 sec\n",
      "Processed 41629 (100.0%) in 0.80 sec. BPR loss is 9.47E-01. Sample per second: 51758\n",
      "SLIM_BPR_Recommender: Epoch 5 of 465. Elapsed time 0.93 sec\n",
      "Processed 41629 (100.0%) in 1.00 sec. BPR loss is 1.14E+00. Sample per second: 41558\n",
      "SLIM_BPR_Recommender: Epoch 6 of 465. Elapsed time 1.13 sec\n",
      "Processed 41629 (100.0%) in 0.20 sec. BPR loss is 1.33E+00. Sample per second: 206492\n",
      "SLIM_BPR_Recommender: Epoch 7 of 465. Elapsed time 1.33 sec\n",
      "Processed 41629 (100.0%) in 0.37 sec. BPR loss is 1.68E+00. Sample per second: 111393\n",
      "SLIM_BPR_Recommender: Epoch 8 of 465. Elapsed time 1.50 sec\n",
      "Processed 41629 (100.0%) in 0.54 sec. BPR loss is 1.78E+00. Sample per second: 77251\n",
      "SLIM_BPR_Recommender: Epoch 9 of 465. Elapsed time 1.67 sec\n",
      "Processed 41629 (100.0%) in 0.72 sec. BPR loss is 2.02E+00. Sample per second: 58105\n",
      "SLIM_BPR_Recommender: Epoch 10 of 465. Elapsed time 1.84 sec\n",
      "Processed 41629 (100.0%) in 0.88 sec. BPR loss is 2.11E+00. Sample per second: 47297\n",
      "SLIM_BPR_Recommender: Epoch 11 of 465. Elapsed time 2.01 sec\n",
      "Processed 41629 (100.0%) in 1.06 sec. BPR loss is 2.33E+00. Sample per second: 39156\n",
      "SLIM_BPR_Recommender: Epoch 12 of 465. Elapsed time 2.19 sec\n",
      "Processed 41629 (100.0%) in 0.23 sec. BPR loss is 2.54E+00. Sample per second: 178049\n",
      "SLIM_BPR_Recommender: Epoch 13 of 465. Elapsed time 2.36 sec\n",
      "Processed 41629 (100.0%) in 0.39 sec. BPR loss is 2.73E+00. Sample per second: 105692\n",
      "SLIM_BPR_Recommender: Epoch 14 of 465. Elapsed time 2.52 sec\n",
      "Processed 41629 (100.0%) in 0.55 sec. BPR loss is 2.87E+00. Sample per second: 75199\n",
      "SLIM_BPR_Recommender: Epoch 15 of 465. Elapsed time 2.68 sec\n",
      "Processed 41629 (100.0%) in 0.71 sec. BPR loss is 2.95E+00. Sample per second: 58932\n",
      "SLIM_BPR_Recommender: Epoch 16 of 465. Elapsed time 2.83 sec\n",
      "Processed 41629 (100.0%) in 0.87 sec. BPR loss is 3.11E+00. Sample per second: 47875\n",
      "SLIM_BPR_Recommender: Epoch 17 of 465. Elapsed time 3.00 sec\n",
      "Processed 41629 (100.0%) in 1.05 sec. BPR loss is 3.26E+00. Sample per second: 39736\n",
      "SLIM_BPR_Recommender: Epoch 18 of 465. Elapsed time 3.17 sec\n",
      "Processed 41629 (100.0%) in 0.21 sec. BPR loss is 3.62E+00. Sample per second: 198901\n",
      "SLIM_BPR_Recommender: Epoch 19 of 465. Elapsed time 3.34 sec\n",
      "Processed 41629 (100.0%) in 0.37 sec. BPR loss is 3.48E+00. Sample per second: 111603\n",
      "SLIM_BPR_Recommender: Epoch 20 of 465. Elapsed time 3.50 sec\n",
      "Processed 41629 (100.0%) in 0.54 sec. BPR loss is 3.80E+00. Sample per second: 76404\n",
      "SLIM_BPR_Recommender: Epoch 21 of 465. Elapsed time 3.67 sec\n",
      "Processed 41629 (100.0%) in 0.75 sec. BPR loss is 3.90E+00. Sample per second: 55165\n",
      "SLIM_BPR_Recommender: Epoch 22 of 465. Elapsed time 3.88 sec\n",
      "Processed 41629 (100.0%) in 0.93 sec. BPR loss is 3.95E+00. Sample per second: 44752\n",
      "SLIM_BPR_Recommender: Epoch 23 of 465. Elapsed time 4.06 sec\n",
      "Processed 41629 (100.0%) in 1.09 sec. BPR loss is 4.21E+00. Sample per second: 38142\n",
      "SLIM_BPR_Recommender: Epoch 24 of 465. Elapsed time 4.22 sec\n",
      "Processed 41629 (100.0%) in 0.25 sec. BPR loss is 4.27E+00. Sample per second: 165969\n",
      "SLIM_BPR_Recommender: Epoch 25 of 465. Elapsed time 4.38 sec\n",
      "Processed 41629 (100.0%) in 0.40 sec. BPR loss is 4.36E+00. Sample per second: 103272\n",
      "SLIM_BPR_Recommender: Epoch 26 of 465. Elapsed time 4.53 sec\n",
      "Processed 41629 (100.0%) in 0.56 sec. BPR loss is 4.55E+00. Sample per second: 74294\n",
      "SLIM_BPR_Recommender: Epoch 27 of 465. Elapsed time 4.69 sec\n",
      "Processed 41629 (100.0%) in 0.73 sec. BPR loss is 4.47E+00. Sample per second: 57178\n",
      "SLIM_BPR_Recommender: Epoch 28 of 465. Elapsed time 4.85 sec\n",
      "Processed 41629 (100.0%) in 0.90 sec. BPR loss is 4.73E+00. Sample per second: 46117\n",
      "SLIM_BPR_Recommender: Epoch 29 of 465. Elapsed time 5.03 sec\n",
      "Processed 41629 (100.0%) in 1.10 sec. BPR loss is 4.84E+00. Sample per second: 37791\n",
      "SLIM_BPR_Recommender: Epoch 30 of 465. Elapsed time 5.23 sec\n",
      "Processed 41629 (100.0%) in 0.29 sec. BPR loss is 4.87E+00. Sample per second: 141824\n",
      "SLIM_BPR_Recommender: Epoch 31 of 465. Elapsed time 5.42 sec\n",
      "Processed 41629 (100.0%) in 0.49 sec. BPR loss is 5.02E+00. Sample per second: 85058\n",
      "SLIM_BPR_Recommender: Epoch 32 of 465. Elapsed time 5.62 sec\n",
      "Processed 41629 (100.0%) in 0.69 sec. BPR loss is 5.01E+00. Sample per second: 60349\n",
      "SLIM_BPR_Recommender: Epoch 33 of 465. Elapsed time 5.82 sec\n",
      "Processed 41629 (100.0%) in 0.90 sec. BPR loss is 5.25E+00. Sample per second: 46173\n",
      "SLIM_BPR_Recommender: Epoch 34 of 465. Elapsed time 6.03 sec\n",
      "Processed 41629 (100.0%) in 1.13 sec. BPR loss is 5.29E+00. Sample per second: 36880\n",
      "SLIM_BPR_Recommender: Epoch 35 of 465. Elapsed time 6.26 sec\n",
      "Processed 41629 (100.0%) in 0.38 sec. BPR loss is 5.57E+00. Sample per second: 108212\n",
      "SLIM_BPR_Recommender: Epoch 36 of 465. Elapsed time 6.51 sec\n",
      "Processed 41629 (100.0%) in 0.63 sec. BPR loss is 5.53E+00. Sample per second: 65951\n",
      "SLIM_BPR_Recommender: Epoch 37 of 465. Elapsed time 6.76 sec\n",
      "Processed 41629 (100.0%) in 0.90 sec. BPR loss is 5.83E+00. Sample per second: 46379\n",
      "SLIM_BPR_Recommender: Epoch 38 of 465. Elapsed time 7.03 sec\n",
      "Processed 41629 (100.0%) in 1.14 sec. BPR loss is 5.77E+00. Sample per second: 36418\n",
      "SLIM_BPR_Recommender: Epoch 39 of 465. Elapsed time 7.27 sec\n",
      "Processed 41629 (100.0%) in 0.37 sec. BPR loss is 6.07E+00. Sample per second: 111976\n",
      "SLIM_BPR_Recommender: Epoch 40 of 465. Elapsed time 7.50 sec\n",
      "Processed 41629 (100.0%) in 0.57 sec. BPR loss is 6.03E+00. Sample per second: 73078\n",
      "SLIM_BPR_Recommender: Epoch 41 of 465. Elapsed time 7.70 sec\n",
      "Processed 41629 (100.0%) in 0.82 sec. BPR loss is 6.05E+00. Sample per second: 50912\n",
      "SLIM_BPR_Recommender: Epoch 42 of 465. Elapsed time 7.94 sec\n",
      "Processed 41629 (100.0%) in 1.03 sec. BPR loss is 6.23E+00. Sample per second: 40322\n",
      "SLIM_BPR_Recommender: Epoch 43 of 465. Elapsed time 8.16 sec\n",
      "Processed 41629 (100.0%) in 0.26 sec. BPR loss is 6.07E+00. Sample per second: 160064\n",
      "SLIM_BPR_Recommender: Epoch 44 of 465. Elapsed time 8.39 sec\n",
      "Processed 41629 (100.0%) in 0.47 sec. BPR loss is 6.30E+00. Sample per second: 89057\n",
      "SLIM_BPR_Recommender: Epoch 45 of 465. Elapsed time 8.59 sec\n",
      "Processed 41629 (100.0%) in 0.67 sec. BPR loss is 6.37E+00. Sample per second: 62246\n",
      "SLIM_BPR_Recommender: Epoch 46 of 465. Elapsed time 8.80 sec\n",
      "Processed 41629 (100.0%) in 0.90 sec. BPR loss is 6.51E+00. Sample per second: 46054\n",
      "SLIM_BPR_Recommender: Epoch 47 of 465. Elapsed time 9.03 sec\n",
      "Processed 41629 (100.0%) in 1.17 sec. BPR loss is 6.37E+00. Sample per second: 35618\n",
      "SLIM_BPR_Recommender: Epoch 48 of 465. Elapsed time 9.30 sec\n",
      "Processed 41629 (100.0%) in 0.40 sec. BPR loss is 6.74E+00. Sample per second: 104360\n",
      "SLIM_BPR_Recommender: Epoch 49 of 465. Elapsed time 9.53 sec\n",
      "Processed 41629 (100.0%) in 0.62 sec. BPR loss is 6.82E+00. Sample per second: 67347\n",
      "SLIM_BPR_Recommender: Epoch 50 of 465. Elapsed time 9.75 sec\n",
      "Processed 41629 (100.0%) in 0.95 sec. BPR loss is 6.76E+00. Sample per second: 43776\n",
      "SLIM_BPR_Recommender: Epoch 51 of 465. Elapsed time 10.08 sec\n",
      "Processed 41629 (100.0%) in 1.22 sec. BPR loss is 6.75E+00. Sample per second: 34212\n",
      "SLIM_BPR_Recommender: Epoch 52 of 465. Elapsed time 10.34 sec\n",
      "Processed 41629 (100.0%) in 0.47 sec. BPR loss is 6.84E+00. Sample per second: 88800\n",
      "SLIM_BPR_Recommender: Epoch 53 of 465. Elapsed time 10.60 sec\n",
      "Processed 41629 (100.0%) in 0.71 sec. BPR loss is 6.81E+00. Sample per second: 58280\n",
      "SLIM_BPR_Recommender: Epoch 54 of 465. Elapsed time 10.84 sec\n",
      "Processed 41629 (100.0%) in 0.94 sec. BPR loss is 7.20E+00. Sample per second: 44381\n",
      "SLIM_BPR_Recommender: Epoch 55 of 465. Elapsed time 11.06 sec\n",
      "Processed 41629 (100.0%) in 1.14 sec. BPR loss is 7.27E+00. Sample per second: 36394\n",
      "SLIM_BPR_Recommender: Epoch 56 of 465. Elapsed time 11.27 sec\n",
      "Processed 41629 (100.0%) in 0.36 sec. BPR loss is 7.50E+00. Sample per second: 116238\n",
      "SLIM_BPR_Recommender: Epoch 57 of 465. Elapsed time 11.49 sec\n",
      "Processed 41629 (100.0%) in 0.56 sec. BPR loss is 7.41E+00. Sample per second: 74074\n",
      "SLIM_BPR_Recommender: Epoch 58 of 465. Elapsed time 11.69 sec\n",
      "Processed 41629 (100.0%) in 0.76 sec. BPR loss is 7.30E+00. Sample per second: 54605\n",
      "SLIM_BPR_Recommender: Epoch 59 of 465. Elapsed time 11.89 sec\n",
      "Processed 41629 (100.0%) in 0.96 sec. BPR loss is 7.69E+00. Sample per second: 43286\n",
      "SLIM_BPR_Recommender: Epoch 60 of 465. Elapsed time 12.09 sec\n",
      "Processed 41629 (100.0%) in 1.17 sec. BPR loss is 7.60E+00. Sample per second: 35609\n",
      "SLIM_BPR_Recommender: Epoch 61 of 465. Elapsed time 12.30 sec\n",
      "Processed 41629 (100.0%) in 0.34 sec. BPR loss is 7.60E+00. Sample per second: 122397\n",
      "SLIM_BPR_Recommender: Epoch 62 of 465. Elapsed time 12.47 sec\n",
      "Processed 41629 (100.0%) in 0.51 sec. BPR loss is 7.69E+00. Sample per second: 81276\n",
      "SLIM_BPR_Recommender: Epoch 63 of 465. Elapsed time 12.64 sec\n",
      "Processed 41629 (100.0%) in 0.69 sec. BPR loss is 7.70E+00. Sample per second: 60566\n",
      "SLIM_BPR_Recommender: Epoch 64 of 465. Elapsed time 12.81 sec\n",
      "Processed 41629 (100.0%) in 0.87 sec. BPR loss is 7.63E+00. Sample per second: 47804\n",
      "SLIM_BPR_Recommender: Epoch 65 of 465. Elapsed time 13.00 sec\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 7.99E+00. Sample per second: 38845\n",
      "SLIM_BPR_Recommender: Epoch 66 of 465. Elapsed time 13.20 sec\n",
      "Processed 41629 (100.0%) in 0.25 sec. BPR loss is 7.99E+00. Sample per second: 168359\n",
      "SLIM_BPR_Recommender: Epoch 67 of 465. Elapsed time 13.37 sec\n",
      "Processed 41629 (100.0%) in 0.43 sec. BPR loss is 8.06E+00. Sample per second: 97534\n",
      "SLIM_BPR_Recommender: Epoch 68 of 465. Elapsed time 13.55 sec\n",
      "Processed 41629 (100.0%) in 0.60 sec. BPR loss is 8.05E+00. Sample per second: 69276\n",
      "SLIM_BPR_Recommender: Epoch 69 of 465. Elapsed time 13.73 sec\n",
      "Processed 41629 (100.0%) in 0.82 sec. BPR loss is 7.93E+00. Sample per second: 50943\n",
      "SLIM_BPR_Recommender: Epoch 70 of 465. Elapsed time 13.94 sec\n",
      "Processed 41629 (100.0%) in 1.01 sec. BPR loss is 8.34E+00. Sample per second: 41292\n",
      "SLIM_BPR_Recommender: Epoch 71 of 465. Elapsed time 14.14 sec\n",
      "Processed 41629 (100.0%) in 0.27 sec. BPR loss is 7.99E+00. Sample per second: 154454\n",
      "SLIM_BPR_Recommender: Epoch 72 of 465. Elapsed time 14.40 sec\n",
      "Processed 41629 (100.0%) in 0.55 sec. BPR loss is 8.10E+00. Sample per second: 75045\n",
      "SLIM_BPR_Recommender: Epoch 73 of 465. Elapsed time 14.68 sec\n",
      "Processed 41629 (100.0%) in 0.81 sec. BPR loss is 7.99E+00. Sample per second: 51666\n",
      "SLIM_BPR_Recommender: Epoch 74 of 465. Elapsed time 14.93 sec\n",
      "Processed 41629 (100.0%) in 1.04 sec. BPR loss is 8.38E+00. Sample per second: 40054\n",
      "SLIM_BPR_Recommender: Epoch 75 of 465. Elapsed time 15.17 sec\n",
      "Processed 41629 (100.0%) in 0.28 sec. BPR loss is 8.13E+00. Sample per second: 150072\n",
      "SLIM_BPR_Recommender: Epoch 76 of 465. Elapsed time 15.40 sec\n",
      "Processed 41629 (100.0%) in 0.46 sec. BPR loss is 8.37E+00. Sample per second: 90217\n",
      "SLIM_BPR_Recommender: Epoch 77 of 465. Elapsed time 15.59 sec\n",
      "Processed 41629 (100.0%) in 0.63 sec. BPR loss is 8.75E+00. Sample per second: 66593\n",
      "SLIM_BPR_Recommender: Epoch 78 of 465. Elapsed time 15.75 sec\n",
      "Processed 41629 (100.0%) in 0.92 sec. BPR loss is 8.69E+00. Sample per second: 45214\n",
      "SLIM_BPR_Recommender: Epoch 79 of 465. Elapsed time 16.05 sec\n",
      "Processed 41629 (100.0%) in 1.10 sec. BPR loss is 8.73E+00. Sample per second: 38007\n",
      "SLIM_BPR_Recommender: Epoch 80 of 465. Elapsed time 16.22 sec\n",
      "Processed 41629 (100.0%) in 0.26 sec. BPR loss is 8.60E+00. Sample per second: 157363\n",
      "SLIM_BPR_Recommender: Epoch 81 of 465. Elapsed time 16.39 sec\n",
      "Processed 41629 (100.0%) in 0.43 sec. BPR loss is 8.70E+00. Sample per second: 96423\n",
      "SLIM_BPR_Recommender: Epoch 82 of 465. Elapsed time 16.56 sec\n",
      "Processed 41629 (100.0%) in 0.59 sec. BPR loss is 8.79E+00. Sample per second: 69971\n",
      "SLIM_BPR_Recommender: Epoch 83 of 465. Elapsed time 16.72 sec\n",
      "Processed 41629 (100.0%) in 0.75 sec. BPR loss is 8.67E+00. Sample per second: 55168\n",
      "SLIM_BPR_Recommender: Epoch 84 of 465. Elapsed time 16.88 sec\n",
      "Processed 41629 (100.0%) in 0.92 sec. BPR loss is 8.98E+00. Sample per second: 45259\n",
      "SLIM_BPR_Recommender: Epoch 85 of 465. Elapsed time 17.05 sec\n",
      "Processed 41629 (100.0%) in 1.08 sec. BPR loss is 8.84E+00. Sample per second: 38439\n",
      "SLIM_BPR_Recommender: Epoch 86 of 465. Elapsed time 17.21 sec\n",
      "Processed 41629 (100.0%) in 0.25 sec. BPR loss is 8.99E+00. Sample per second: 164817\n",
      "SLIM_BPR_Recommender: Epoch 87 of 465. Elapsed time 17.38 sec\n",
      "Processed 41629 (100.0%) in 0.46 sec. BPR loss is 9.07E+00. Sample per second: 90909\n",
      "SLIM_BPR_Recommender: Epoch 88 of 465. Elapsed time 17.58 sec\n",
      "Processed 41629 (100.0%) in 0.66 sec. BPR loss is 9.25E+00. Sample per second: 63281\n",
      "SLIM_BPR_Recommender: Epoch 89 of 465. Elapsed time 17.78 sec\n",
      "Processed 41629 (100.0%) in 0.86 sec. BPR loss is 9.02E+00. Sample per second: 48534\n",
      "SLIM_BPR_Recommender: Epoch 90 of 465. Elapsed time 17.98 sec\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 9.29E+00. Sample per second: 38960\n",
      "SLIM_BPR_Recommender: Epoch 91 of 465. Elapsed time 18.20 sec\n",
      "Processed 41629 (100.0%) in 0.26 sec. BPR loss is 9.59E+00. Sample per second: 157141\n",
      "SLIM_BPR_Recommender: Epoch 92 of 465. Elapsed time 18.39 sec\n",
      "Processed 41629 (100.0%) in 0.45 sec. BPR loss is 9.16E+00. Sample per second: 93134\n",
      "SLIM_BPR_Recommender: Epoch 93 of 465. Elapsed time 18.57 sec\n",
      "Processed 41629 (100.0%) in 0.66 sec. BPR loss is 9.48E+00. Sample per second: 62719\n",
      "SLIM_BPR_Recommender: Epoch 94 of 465. Elapsed time 18.79 sec\n",
      "Processed 41629 (100.0%) in 0.86 sec. BPR loss is 9.47E+00. Sample per second: 48566\n",
      "SLIM_BPR_Recommender: Epoch 95 of 465. Elapsed time 18.98 sec\n",
      "Processed 41629 (100.0%) in 1.08 sec. BPR loss is 9.59E+00. Sample per second: 38498\n",
      "SLIM_BPR_Recommender: Epoch 96 of 465. Elapsed time 19.21 sec\n",
      "Processed 41629 (100.0%) in 0.29 sec. BPR loss is 9.78E+00. Sample per second: 143213\n",
      "SLIM_BPR_Recommender: Epoch 97 of 465. Elapsed time 19.42 sec\n",
      "Processed 41629 (100.0%) in 0.49 sec. BPR loss is 9.48E+00. Sample per second: 84773\n",
      "SLIM_BPR_Recommender: Epoch 98 of 465. Elapsed time 19.62 sec\n",
      "Processed 41629 (100.0%) in 0.69 sec. BPR loss is 9.50E+00. Sample per second: 60597\n",
      "SLIM_BPR_Recommender: Epoch 99 of 465. Elapsed time 19.81 sec\n",
      "Processed 41629 (100.0%) in 0.88 sec. BPR loss is 9.76E+00. Sample per second: 47099\n",
      "SLIM_BPR_Recommender: Epoch 100 of 465. Elapsed time 20.01 sec\n",
      "Processed 41629 (100.0%) in 1.09 sec. BPR loss is 9.65E+00. Sample per second: 38116\n",
      "SLIM_BPR_Recommender: Epoch 101 of 465. Elapsed time 20.22 sec\n",
      "Processed 41629 (100.0%) in 0.30 sec. BPR loss is 9.86E+00. Sample per second: 140622\n",
      "SLIM_BPR_Recommender: Epoch 102 of 465. Elapsed time 20.42 sec\n",
      "Processed 41629 (100.0%) in 0.49 sec. BPR loss is 9.54E+00. Sample per second: 85135\n",
      "SLIM_BPR_Recommender: Epoch 103 of 465. Elapsed time 20.62 sec\n",
      "Processed 41629 (100.0%) in 0.70 sec. BPR loss is 1.00E+01. Sample per second: 59825\n",
      "SLIM_BPR_Recommender: Epoch 104 of 465. Elapsed time 20.82 sec\n",
      "Processed 41629 (100.0%) in 0.90 sec. BPR loss is 9.67E+00. Sample per second: 46425\n",
      "SLIM_BPR_Recommender: Epoch 105 of 465. Elapsed time 21.02 sec\n",
      "Processed 41629 (100.0%) in 1.11 sec. BPR loss is 9.99E+00. Sample per second: 37421\n",
      "SLIM_BPR_Recommender: Epoch 106 of 465. Elapsed time 21.24 sec\n",
      "Processed 41629 (100.0%) in 0.32 sec. BPR loss is 9.64E+00. Sample per second: 130789\n",
      "SLIM_BPR_Recommender: Epoch 107 of 465. Elapsed time 21.45 sec\n",
      "Processed 41629 (100.0%) in 0.53 sec. BPR loss is 9.93E+00. Sample per second: 79200\n",
      "SLIM_BPR_Recommender: Epoch 108 of 465. Elapsed time 21.65 sec\n",
      "Processed 41629 (100.0%) in 0.72 sec. BPR loss is 1.01E+01. Sample per second: 57458\n",
      "SLIM_BPR_Recommender: Epoch 109 of 465. Elapsed time 21.85 sec\n",
      "Processed 41629 (100.0%) in 0.95 sec. BPR loss is 1.02E+01. Sample per second: 43674\n",
      "SLIM_BPR_Recommender: Epoch 110 of 465. Elapsed time 22.08 sec\n",
      "Processed 41629 (100.0%) in 1.16 sec. BPR loss is 1.00E+01. Sample per second: 35734\n",
      "SLIM_BPR_Recommender: Epoch 111 of 465. Elapsed time 22.29 sec\n",
      "Processed 41629 (100.0%) in 0.37 sec. BPR loss is 1.01E+01. Sample per second: 111215\n",
      "SLIM_BPR_Recommender: Epoch 112 of 465. Elapsed time 22.50 sec\n",
      "Processed 41629 (100.0%) in 0.59 sec. BPR loss is 1.02E+01. Sample per second: 70317\n",
      "SLIM_BPR_Recommender: Epoch 113 of 465. Elapsed time 22.72 sec\n",
      "Processed 41629 (100.0%) in 0.79 sec. BPR loss is 9.87E+00. Sample per second: 52467\n",
      "SLIM_BPR_Recommender: Epoch 114 of 465. Elapsed time 22.92 sec\n",
      "Processed 41629 (100.0%) in 0.98 sec. BPR loss is 1.01E+01. Sample per second: 42312\n",
      "SLIM_BPR_Recommender: Epoch 115 of 465. Elapsed time 23.11 sec\n",
      "Processed 41629 (100.0%) in 1.16 sec. BPR loss is 1.01E+01. Sample per second: 35872\n",
      "SLIM_BPR_Recommender: Epoch 116 of 465. Elapsed time 23.29 sec\n",
      "Processed 41629 (100.0%) in 0.36 sec. BPR loss is 1.03E+01. Sample per second: 116172\n",
      "SLIM_BPR_Recommender: Epoch 117 of 465. Elapsed time 23.49 sec\n",
      "Processed 41629 (100.0%) in 0.55 sec. BPR loss is 1.04E+01. Sample per second: 75649\n",
      "SLIM_BPR_Recommender: Epoch 118 of 465. Elapsed time 23.68 sec\n",
      "Processed 41629 (100.0%) in 0.72 sec. BPR loss is 1.03E+01. Sample per second: 57901\n",
      "SLIM_BPR_Recommender: Epoch 119 of 465. Elapsed time 23.85 sec\n",
      "Processed 41629 (100.0%) in 0.89 sec. BPR loss is 1.04E+01. Sample per second: 46979\n",
      "SLIM_BPR_Recommender: Epoch 120 of 465. Elapsed time 24.01 sec\n",
      "Processed 41629 (100.0%) in 1.05 sec. BPR loss is 1.02E+01. Sample per second: 39524\n",
      "SLIM_BPR_Recommender: Epoch 121 of 465. Elapsed time 24.18 sec\n",
      "Processed 41629 (100.0%) in 0.21 sec. BPR loss is 1.03E+01. Sample per second: 201094\n",
      "SLIM_BPR_Recommender: Epoch 122 of 465. Elapsed time 24.33 sec\n",
      "Processed 41629 (100.0%) in 0.37 sec. BPR loss is 1.05E+01. Sample per second: 111554\n",
      "SLIM_BPR_Recommender: Epoch 123 of 465. Elapsed time 24.50 sec\n",
      "Processed 41629 (100.0%) in 0.54 sec. BPR loss is 1.04E+01. Sample per second: 76833\n",
      "SLIM_BPR_Recommender: Epoch 124 of 465. Elapsed time 24.67 sec\n",
      "Processed 41629 (100.0%) in 0.71 sec. BPR loss is 1.04E+01. Sample per second: 58295\n",
      "SLIM_BPR_Recommender: Epoch 125 of 465. Elapsed time 24.84 sec\n",
      "Processed 41629 (100.0%) in 0.89 sec. BPR loss is 1.07E+01. Sample per second: 46816\n",
      "SLIM_BPR_Recommender: Epoch 126 of 465. Elapsed time 25.02 sec\n",
      "Processed 41629 (100.0%) in 1.08 sec. BPR loss is 1.08E+01. Sample per second: 38538\n",
      "SLIM_BPR_Recommender: Epoch 127 of 465. Elapsed time 25.21 sec\n",
      "Processed 41629 (100.0%) in 0.25 sec. BPR loss is 1.04E+01. Sample per second: 169320\n",
      "SLIM_BPR_Recommender: Epoch 128 of 465. Elapsed time 25.37 sec\n",
      "Processed 41629 (100.0%) in 0.41 sec. BPR loss is 1.07E+01. Sample per second: 101648\n",
      "SLIM_BPR_Recommender: Epoch 129 of 465. Elapsed time 25.54 sec\n",
      "Processed 41629 (100.0%) in 0.58 sec. BPR loss is 1.07E+01. Sample per second: 72124\n",
      "SLIM_BPR_Recommender: Epoch 130 of 465. Elapsed time 25.70 sec\n",
      "Processed 41629 (100.0%) in 0.75 sec. BPR loss is 1.09E+01. Sample per second: 55816\n",
      "SLIM_BPR_Recommender: Epoch 131 of 465. Elapsed time 25.87 sec\n",
      "Processed 41629 (100.0%) in 0.92 sec. BPR loss is 1.08E+01. Sample per second: 45449\n",
      "SLIM_BPR_Recommender: Epoch 132 of 465. Elapsed time 26.04 sec\n",
      "Processed 41629 (100.0%) in 1.09 sec. BPR loss is 1.07E+01. Sample per second: 38138\n",
      "SLIM_BPR_Recommender: Epoch 133 of 465. Elapsed time 26.22 sec\n",
      "Processed 41629 (100.0%) in 0.25 sec. BPR loss is 1.08E+01. Sample per second: 164090\n",
      "SLIM_BPR_Recommender: Epoch 134 of 465. Elapsed time 26.38 sec\n",
      "Processed 41629 (100.0%) in 0.42 sec. BPR loss is 1.08E+01. Sample per second: 98917\n",
      "SLIM_BPR_Recommender: Epoch 135 of 465. Elapsed time 26.55 sec\n",
      "Processed 41629 (100.0%) in 0.58 sec. BPR loss is 1.09E+01. Sample per second: 71279\n",
      "SLIM_BPR_Recommender: Epoch 136 of 465. Elapsed time 26.71 sec\n",
      "Processed 41629 (100.0%) in 0.75 sec. BPR loss is 1.09E+01. Sample per second: 55635\n",
      "SLIM_BPR_Recommender: Epoch 137 of 465. Elapsed time 26.87 sec\n",
      "Processed 41629 (100.0%) in 0.91 sec. BPR loss is 1.11E+01. Sample per second: 45627\n",
      "SLIM_BPR_Recommender: Epoch 138 of 465. Elapsed time 27.04 sec\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 1.10E+01. Sample per second: 38924\n",
      "SLIM_BPR_Recommender: Epoch 139 of 465. Elapsed time 27.20 sec\n",
      "Processed 41629 (100.0%) in 0.23 sec. BPR loss is 1.11E+01. Sample per second: 182796\n",
      "SLIM_BPR_Recommender: Epoch 140 of 465. Elapsed time 27.35 sec\n",
      "Processed 41629 (100.0%) in 0.40 sec. BPR loss is 1.09E+01. Sample per second: 104753\n",
      "SLIM_BPR_Recommender: Epoch 141 of 465. Elapsed time 27.52 sec\n",
      "Processed 41629 (100.0%) in 0.57 sec. BPR loss is 1.10E+01. Sample per second: 72783\n",
      "SLIM_BPR_Recommender: Epoch 142 of 465. Elapsed time 27.70 sec\n",
      "Processed 41629 (100.0%) in 0.73 sec. BPR loss is 1.14E+01. Sample per second: 57008\n",
      "SLIM_BPR_Recommender: Epoch 143 of 465. Elapsed time 27.86 sec\n",
      "Processed 41629 (100.0%) in 0.89 sec. BPR loss is 1.12E+01. Sample per second: 46910\n",
      "SLIM_BPR_Recommender: Epoch 144 of 465. Elapsed time 28.01 sec\n",
      "Processed 41629 (100.0%) in 1.05 sec. BPR loss is 1.13E+01. Sample per second: 39661\n",
      "SLIM_BPR_Recommender: Epoch 145 of 465. Elapsed time 28.18 sec\n",
      "Processed 41629 (100.0%) in 0.21 sec. BPR loss is 1.13E+01. Sample per second: 201247\n",
      "SLIM_BPR_Recommender: Epoch 146 of 465. Elapsed time 28.33 sec\n",
      "Processed 41629 (100.0%) in 0.37 sec. BPR loss is 1.13E+01. Sample per second: 113719\n",
      "SLIM_BPR_Recommender: Epoch 147 of 465. Elapsed time 28.49 sec\n",
      "Processed 41629 (100.0%) in 0.54 sec. BPR loss is 1.13E+01. Sample per second: 76718\n",
      "SLIM_BPR_Recommender: Epoch 148 of 465. Elapsed time 28.67 sec\n",
      "Processed 41629 (100.0%) in 0.71 sec. BPR loss is 1.14E+01. Sample per second: 58284\n",
      "SLIM_BPR_Recommender: Epoch 149 of 465. Elapsed time 28.84 sec\n",
      "Processed 41629 (100.0%) in 0.90 sec. BPR loss is 1.13E+01. Sample per second: 46370\n",
      "SLIM_BPR_Recommender: Epoch 150 of 465. Elapsed time 29.02 sec\n",
      "Processed 41629 (100.0%) in 1.09 sec. BPR loss is 1.13E+01. Sample per second: 38097\n",
      "SLIM_BPR_Recommender: Epoch 151 of 465. Elapsed time 29.22 sec\n",
      "Processed 41629 (100.0%) in 0.30 sec. BPR loss is 1.13E+01. Sample per second: 139448\n",
      "SLIM_BPR_Recommender: Epoch 152 of 465. Elapsed time 29.43 sec\n",
      "Processed 41629 (100.0%) in 0.48 sec. BPR loss is 1.15E+01. Sample per second: 87431\n",
      "SLIM_BPR_Recommender: Epoch 153 of 465. Elapsed time 29.60 sec\n",
      "Processed 41629 (100.0%) in 0.68 sec. BPR loss is 1.15E+01. Sample per second: 61224\n",
      "SLIM_BPR_Recommender: Epoch 154 of 465. Elapsed time 29.81 sec\n",
      "Processed 41629 (100.0%) in 0.87 sec. BPR loss is 1.16E+01. Sample per second: 47774\n",
      "SLIM_BPR_Recommender: Epoch 155 of 465. Elapsed time 30.00 sec\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 1.14E+01. Sample per second: 39021\n",
      "SLIM_BPR_Recommender: Epoch 156 of 465. Elapsed time 30.19 sec\n",
      "Processed 41629 (100.0%) in 0.28 sec. BPR loss is 1.15E+01. Sample per second: 149431\n",
      "SLIM_BPR_Recommender: Epoch 157 of 465. Elapsed time 30.41 sec\n",
      "Processed 41629 (100.0%) in 0.51 sec. BPR loss is 1.17E+01. Sample per second: 81909\n",
      "SLIM_BPR_Recommender: Epoch 158 of 465. Elapsed time 30.64 sec\n",
      "Processed 41629 (100.0%) in 0.73 sec. BPR loss is 1.16E+01. Sample per second: 57144\n",
      "SLIM_BPR_Recommender: Epoch 159 of 465. Elapsed time 30.86 sec\n",
      "Processed 41629 (100.0%) in 0.93 sec. BPR loss is 1.16E+01. Sample per second: 44770\n",
      "SLIM_BPR_Recommender: Epoch 160 of 465. Elapsed time 31.06 sec\n",
      "Processed 41629 (100.0%) in 1.16 sec. BPR loss is 1.19E+01. Sample per second: 35795\n",
      "SLIM_BPR_Recommender: Epoch 161 of 465. Elapsed time 31.29 sec\n",
      "Processed 41629 (100.0%) in 0.36 sec. BPR loss is 1.17E+01. Sample per second: 114106\n",
      "SLIM_BPR_Recommender: Epoch 162 of 465. Elapsed time 31.49 sec\n",
      "Processed 41629 (100.0%) in 0.57 sec. BPR loss is 1.17E+01. Sample per second: 73583\n",
      "SLIM_BPR_Recommender: Epoch 163 of 465. Elapsed time 31.69 sec\n",
      "Processed 41629 (100.0%) in 0.76 sec. BPR loss is 1.18E+01. Sample per second: 54798\n",
      "SLIM_BPR_Recommender: Epoch 164 of 465. Elapsed time 31.89 sec\n",
      "Processed 41629 (100.0%) in 0.96 sec. BPR loss is 1.17E+01. Sample per second: 43451\n",
      "SLIM_BPR_Recommender: Epoch 165 of 465. Elapsed time 32.09 sec\n",
      "Processed 41629 (100.0%) in 1.18 sec. BPR loss is 1.17E+01. Sample per second: 35330\n",
      "SLIM_BPR_Recommender: Epoch 166 of 465. Elapsed time 32.30 sec\n",
      "Processed 41629 (100.0%) in 0.38 sec. BPR loss is 1.19E+01. Sample per second: 109214\n",
      "SLIM_BPR_Recommender: Epoch 167 of 465. Elapsed time 32.51 sec\n",
      "Processed 41629 (100.0%) in 0.58 sec. BPR loss is 1.21E+01. Sample per second: 71766\n",
      "SLIM_BPR_Recommender: Epoch 168 of 465. Elapsed time 32.71 sec\n",
      "Processed 41629 (100.0%) in 0.78 sec. BPR loss is 1.20E+01. Sample per second: 53241\n",
      "SLIM_BPR_Recommender: Epoch 169 of 465. Elapsed time 32.91 sec\n",
      "Processed 41629 (100.0%) in 0.97 sec. BPR loss is 1.18E+01. Sample per second: 42900\n",
      "SLIM_BPR_Recommender: Epoch 170 of 465. Elapsed time 33.10 sec\n",
      "Processed 41629 (100.0%) in 1.17 sec. BPR loss is 1.19E+01. Sample per second: 35618\n",
      "SLIM_BPR_Recommender: Epoch 171 of 465. Elapsed time 33.30 sec\n",
      "Processed 41629 (100.0%) in 0.35 sec. BPR loss is 1.20E+01. Sample per second: 117998\n",
      "SLIM_BPR_Recommender: Epoch 172 of 465. Elapsed time 33.48 sec\n",
      "Processed 41629 (100.0%) in 0.55 sec. BPR loss is 1.20E+01. Sample per second: 76142\n",
      "SLIM_BPR_Recommender: Epoch 173 of 465. Elapsed time 33.67 sec\n",
      "Processed 41629 (100.0%) in 0.85 sec. BPR loss is 1.21E+01. Sample per second: 48902\n",
      "SLIM_BPR_Recommender: Epoch 174 of 465. Elapsed time 33.98 sec\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 1.21E+01. Sample per second: 38814\n",
      "SLIM_BPR_Recommender: Epoch 175 of 465. Elapsed time 34.20 sec\n",
      "Processed 41629 (100.0%) in 0.27 sec. BPR loss is 1.19E+01. Sample per second: 154218\n",
      "SLIM_BPR_Recommender: Epoch 176 of 465. Elapsed time 34.40 sec\n",
      "Processed 41629 (100.0%) in 0.47 sec. BPR loss is 1.23E+01. Sample per second: 88140\n",
      "SLIM_BPR_Recommender: Epoch 177 of 465. Elapsed time 34.60 sec\n",
      "Processed 41629 (100.0%) in 0.66 sec. BPR loss is 1.21E+01. Sample per second: 62764\n",
      "SLIM_BPR_Recommender: Epoch 178 of 465. Elapsed time 34.79 sec\n",
      "Processed 41629 (100.0%) in 0.87 sec. BPR loss is 1.22E+01. Sample per second: 48036\n",
      "SLIM_BPR_Recommender: Epoch 179 of 465. Elapsed time 34.99 sec\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 1.21E+01. Sample per second: 39033\n",
      "SLIM_BPR_Recommender: Epoch 180 of 465. Elapsed time 35.19 sec\n",
      "Processed 41629 (100.0%) in 0.29 sec. BPR loss is 1.26E+01. Sample per second: 145959\n",
      "SLIM_BPR_Recommender: Epoch 181 of 465. Elapsed time 35.41 sec\n",
      "Processed 41629 (100.0%) in 0.47 sec. BPR loss is 1.20E+01. Sample per second: 88718\n",
      "SLIM_BPR_Recommender: Epoch 182 of 465. Elapsed time 35.60 sec\n",
      "Processed 41629 (100.0%) in 0.64 sec. BPR loss is 1.23E+01. Sample per second: 64814\n",
      "SLIM_BPR_Recommender: Epoch 183 of 465. Elapsed time 35.77 sec\n",
      "Processed 41629 (100.0%) in 0.81 sec. BPR loss is 1.23E+01. Sample per second: 51623\n",
      "SLIM_BPR_Recommender: Epoch 184 of 465. Elapsed time 35.93 sec\n",
      "Processed 41629 (100.0%) in 0.97 sec. BPR loss is 1.25E+01. Sample per second: 42804\n",
      "SLIM_BPR_Recommender: Epoch 185 of 465. Elapsed time 36.10 sec\n",
      "Processed 41629 (100.0%) in 1.14 sec. BPR loss is 1.24E+01. Sample per second: 36463\n",
      "SLIM_BPR_Recommender: Epoch 186 of 465. Elapsed time 36.27 sec\n",
      "Processed 41629 (100.0%) in 0.30 sec. BPR loss is 1.23E+01. Sample per second: 136990\n",
      "SLIM_BPR_Recommender: Epoch 187 of 465. Elapsed time 36.43 sec\n",
      "Processed 41629 (100.0%) in 0.47 sec. BPR loss is 1.25E+01. Sample per second: 89318\n",
      "SLIM_BPR_Recommender: Epoch 188 of 465. Elapsed time 36.59 sec\n",
      "Processed 41629 (100.0%) in 0.64 sec. BPR loss is 1.25E+01. Sample per second: 64823\n",
      "SLIM_BPR_Recommender: Epoch 189 of 465. Elapsed time 36.77 sec\n",
      "Processed 41629 (100.0%) in 0.81 sec. BPR loss is 1.28E+01. Sample per second: 51513\n",
      "SLIM_BPR_Recommender: Epoch 190 of 465. Elapsed time 36.93 sec\n",
      "Processed 41629 (100.0%) in 1.00 sec. BPR loss is 1.26E+01. Sample per second: 41504\n",
      "SLIM_BPR_Recommender: Epoch 191 of 465. Elapsed time 37.13 sec\n",
      "Processed 41629 (100.0%) in 0.19 sec. BPR loss is 1.23E+01. Sample per second: 215125\n",
      "SLIM_BPR_Recommender: Epoch 192 of 465. Elapsed time 37.32 sec\n",
      "Processed 41629 (100.0%) in 0.36 sec. BPR loss is 1.27E+01. Sample per second: 115913\n",
      "SLIM_BPR_Recommender: Epoch 193 of 465. Elapsed time 37.49 sec\n",
      "Processed 41629 (100.0%) in 0.53 sec. BPR loss is 1.25E+01. Sample per second: 78944\n",
      "SLIM_BPR_Recommender: Epoch 194 of 465. Elapsed time 37.65 sec\n",
      "Processed 41629 (100.0%) in 0.69 sec. BPR loss is 1.24E+01. Sample per second: 60639\n",
      "SLIM_BPR_Recommender: Epoch 195 of 465. Elapsed time 37.81 sec\n",
      "Processed 41629 (100.0%) in 0.84 sec. BPR loss is 1.27E+01. Sample per second: 49366\n",
      "SLIM_BPR_Recommender: Epoch 196 of 465. Elapsed time 37.97 sec\n",
      "Processed 41629 (100.0%) in 1.00 sec. BPR loss is 1.25E+01. Sample per second: 41443\n",
      "SLIM_BPR_Recommender: Epoch 197 of 465. Elapsed time 38.13 sec\n",
      "Processed 41629 (100.0%) in 0.16 sec. BPR loss is 1.27E+01. Sample per second: 263077\n",
      "SLIM_BPR_Recommender: Epoch 198 of 465. Elapsed time 38.29 sec\n",
      "Processed 41629 (100.0%) in 0.31 sec. BPR loss is 1.26E+01. Sample per second: 131961\n",
      "SLIM_BPR_Recommender: Epoch 199 of 465. Elapsed time 38.44 sec\n",
      "Processed 41629 (100.0%) in 0.48 sec. BPR loss is 1.27E+01. Sample per second: 87427\n",
      "SLIM_BPR_Recommender: Epoch 200 of 465. Elapsed time 38.60 sec\n",
      "Processed 41629 (100.0%) in 0.64 sec. BPR loss is 1.27E+01. Sample per second: 65165\n",
      "SLIM_BPR_Recommender: Epoch 201 of 465. Elapsed time 38.77 sec\n",
      "Processed 41629 (100.0%) in 0.83 sec. BPR loss is 1.27E+01. Sample per second: 50380\n",
      "SLIM_BPR_Recommender: Epoch 202 of 465. Elapsed time 38.95 sec\n",
      "Processed 41629 (100.0%) in 0.98 sec. BPR loss is 1.28E+01. Sample per second: 42369\n",
      "SLIM_BPR_Recommender: Epoch 203 of 465. Elapsed time 39.11 sec\n",
      "Processed 41629 (100.0%) in 1.14 sec. BPR loss is 1.28E+01. Sample per second: 36599\n",
      "SLIM_BPR_Recommender: Epoch 204 of 465. Elapsed time 39.26 sec\n",
      "Processed 41629 (100.0%) in 0.30 sec. BPR loss is 1.29E+01. Sample per second: 140324\n",
      "SLIM_BPR_Recommender: Epoch 205 of 465. Elapsed time 39.42 sec\n",
      "Processed 41629 (100.0%) in 0.46 sec. BPR loss is 1.27E+01. Sample per second: 90913\n",
      "SLIM_BPR_Recommender: Epoch 206 of 465. Elapsed time 39.58 sec\n",
      "Processed 41629 (100.0%) in 0.63 sec. BPR loss is 1.30E+01. Sample per second: 66253\n",
      "SLIM_BPR_Recommender: Epoch 207 of 465. Elapsed time 39.75 sec\n",
      "Processed 41629 (100.0%) in 0.80 sec. BPR loss is 1.28E+01. Sample per second: 52231\n",
      "SLIM_BPR_Recommender: Epoch 208 of 465. Elapsed time 39.92 sec\n",
      "Processed 41629 (100.0%) in 0.97 sec. BPR loss is 1.31E+01. Sample per second: 42999\n",
      "SLIM_BPR_Recommender: Epoch 209 of 465. Elapsed time 40.09 sec\n",
      "Processed 41629 (100.0%) in 1.13 sec. BPR loss is 1.29E+01. Sample per second: 36702\n",
      "SLIM_BPR_Recommender: Epoch 210 of 465. Elapsed time 40.26 sec\n",
      "Processed 41629 (100.0%) in 0.30 sec. BPR loss is 1.32E+01. Sample per second: 138115\n",
      "SLIM_BPR_Recommender: Epoch 211 of 465. Elapsed time 40.43 sec\n",
      "Processed 41629 (100.0%) in 0.47 sec. BPR loss is 1.31E+01. Sample per second: 87914\n",
      "SLIM_BPR_Recommender: Epoch 212 of 465. Elapsed time 40.60 sec\n",
      "Processed 41629 (100.0%) in 0.68 sec. BPR loss is 1.32E+01. Sample per second: 61588\n",
      "SLIM_BPR_Recommender: Epoch 213 of 465. Elapsed time 40.80 sec\n",
      "Processed 41629 (100.0%) in 0.88 sec. BPR loss is 1.33E+01. Sample per second: 47158\n",
      "SLIM_BPR_Recommender: Epoch 214 of 465. Elapsed time 41.01 sec\n",
      "Processed 41629 (100.0%) in 1.09 sec. BPR loss is 1.31E+01. Sample per second: 38295\n",
      "SLIM_BPR_Recommender: Epoch 215 of 465. Elapsed time 41.21 sec\n",
      "Processed 41629 (100.0%) in 0.29 sec. BPR loss is 1.29E+01. Sample per second: 143562\n",
      "SLIM_BPR_Recommender: Epoch 216 of 465. Elapsed time 41.42 sec\n",
      "Processed 41629 (100.0%) in 0.49 sec. BPR loss is 1.31E+01. Sample per second: 84383\n",
      "SLIM_BPR_Recommender: Epoch 217 of 465. Elapsed time 41.62 sec\n",
      "Processed 41629 (100.0%) in 0.69 sec. BPR loss is 1.33E+01. Sample per second: 60572\n",
      "SLIM_BPR_Recommender: Epoch 218 of 465. Elapsed time 41.81 sec\n",
      "Processed 41629 (100.0%) in 0.88 sec. BPR loss is 1.32E+01. Sample per second: 47294\n",
      "SLIM_BPR_Recommender: Epoch 219 of 465. Elapsed time 42.01 sec\n",
      "Processed 41629 (100.0%) in 1.08 sec. BPR loss is 1.32E+01. Sample per second: 38702\n",
      "SLIM_BPR_Recommender: Epoch 220 of 465. Elapsed time 42.20 sec\n",
      "Processed 41629 (100.0%) in 0.29 sec. BPR loss is 1.34E+01. Sample per second: 145586\n",
      "SLIM_BPR_Recommender: Epoch 221 of 465. Elapsed time 42.41 sec\n",
      "Processed 41629 (100.0%) in 0.48 sec. BPR loss is 1.31E+01. Sample per second: 85956\n",
      "SLIM_BPR_Recommender: Epoch 222 of 465. Elapsed time 42.61 sec\n",
      "Processed 41629 (100.0%) in 0.69 sec. BPR loss is 1.32E+01. Sample per second: 60577\n",
      "SLIM_BPR_Recommender: Epoch 223 of 465. Elapsed time 42.81 sec\n",
      "Processed 41629 (100.0%) in 0.90 sec. BPR loss is 1.31E+01. Sample per second: 46436\n",
      "SLIM_BPR_Recommender: Epoch 224 of 465. Elapsed time 43.02 sec\n",
      "Processed 41629 (100.0%) in 1.09 sec. BPR loss is 1.32E+01. Sample per second: 38368\n",
      "SLIM_BPR_Recommender: Epoch 225 of 465. Elapsed time 43.21 sec\n",
      "Processed 41629 (100.0%) in 0.28 sec. BPR loss is 1.33E+01. Sample per second: 149515\n",
      "SLIM_BPR_Recommender: Epoch 226 of 465. Elapsed time 43.41 sec\n",
      "Processed 41629 (100.0%) in 0.49 sec. BPR loss is 1.35E+01. Sample per second: 85610\n",
      "SLIM_BPR_Recommender: Epoch 227 of 465. Elapsed time 43.61 sec\n",
      "Processed 41629 (100.0%) in 0.68 sec. BPR loss is 1.34E+01. Sample per second: 61249\n",
      "SLIM_BPR_Recommender: Epoch 228 of 465. Elapsed time 43.81 sec\n",
      "Processed 41629 (100.0%) in 0.87 sec. BPR loss is 1.34E+01. Sample per second: 47623\n",
      "SLIM_BPR_Recommender: Epoch 229 of 465. Elapsed time 44.00 sec\n",
      "Processed 41629 (100.0%) in 1.06 sec. BPR loss is 1.36E+01. Sample per second: 39287\n",
      "SLIM_BPR_Recommender: Epoch 230 of 465. Elapsed time 44.19 sec\n",
      "Processed 41629 (100.0%) in 0.25 sec. BPR loss is 1.35E+01. Sample per second: 165162\n",
      "SLIM_BPR_Recommender: Epoch 231 of 465. Elapsed time 44.38 sec\n",
      "Processed 41629 (100.0%) in 0.45 sec. BPR loss is 1.36E+01. Sample per second: 91609\n",
      "SLIM_BPR_Recommender: Epoch 232 of 465. Elapsed time 44.58 sec\n",
      "Processed 41629 (100.0%) in 0.64 sec. BPR loss is 1.35E+01. Sample per second: 64899\n",
      "SLIM_BPR_Recommender: Epoch 233 of 465. Elapsed time 44.77 sec\n",
      "Processed 41629 (100.0%) in 0.83 sec. BPR loss is 1.34E+01. Sample per second: 50401\n",
      "SLIM_BPR_Recommender: Epoch 234 of 465. Elapsed time 44.95 sec\n",
      "Processed 41629 (100.0%) in 1.02 sec. BPR loss is 1.37E+01. Sample per second: 40738\n",
      "SLIM_BPR_Recommender: Epoch 235 of 465. Elapsed time 45.15 sec\n",
      "Processed 41629 (100.0%) in 0.23 sec. BPR loss is 1.34E+01. Sample per second: 184417\n",
      "SLIM_BPR_Recommender: Epoch 236 of 465. Elapsed time 45.35 sec\n",
      "Processed 41629 (100.0%) in 0.42 sec. BPR loss is 1.36E+01. Sample per second: 98496\n",
      "SLIM_BPR_Recommender: Epoch 237 of 465. Elapsed time 45.55 sec\n",
      "Processed 41629 (100.0%) in 0.62 sec. BPR loss is 1.39E+01. Sample per second: 67088\n",
      "SLIM_BPR_Recommender: Epoch 238 of 465. Elapsed time 45.75 sec\n",
      "Processed 41629 (100.0%) in 0.86 sec. BPR loss is 1.37E+01. Sample per second: 48566\n",
      "SLIM_BPR_Recommender: Epoch 239 of 465. Elapsed time 45.98 sec\n",
      "Processed 41629 (100.0%) in 1.08 sec. BPR loss is 1.35E+01. Sample per second: 38694\n",
      "SLIM_BPR_Recommender: Epoch 240 of 465. Elapsed time 46.20 sec\n",
      "Processed 41629 (100.0%) in 0.31 sec. BPR loss is 1.36E+01. Sample per second: 135609\n",
      "SLIM_BPR_Recommender: Epoch 241 of 465. Elapsed time 46.44 sec\n",
      "Processed 41629 (100.0%) in 0.51 sec. BPR loss is 1.38E+01. Sample per second: 81970\n",
      "SLIM_BPR_Recommender: Epoch 242 of 465. Elapsed time 46.63 sec\n",
      "Processed 41629 (100.0%) in 0.72 sec. BPR loss is 1.36E+01. Sample per second: 57846\n",
      "SLIM_BPR_Recommender: Epoch 243 of 465. Elapsed time 46.85 sec\n",
      "Processed 41629 (100.0%) in 0.92 sec. BPR loss is 1.39E+01. Sample per second: 45492\n",
      "SLIM_BPR_Recommender: Epoch 244 of 465. Elapsed time 47.04 sec\n",
      "Processed 41629 (100.0%) in 1.09 sec. BPR loss is 1.38E+01. Sample per second: 38323\n",
      "SLIM_BPR_Recommender: Epoch 245 of 465. Elapsed time 47.21 sec\n",
      "Processed 41629 (100.0%) in 0.25 sec. BPR loss is 1.35E+01. Sample per second: 166907\n",
      "SLIM_BPR_Recommender: Epoch 246 of 465. Elapsed time 47.38 sec\n",
      "Processed 41629 (100.0%) in 0.42 sec. BPR loss is 1.36E+01. Sample per second: 99934\n",
      "SLIM_BPR_Recommender: Epoch 247 of 465. Elapsed time 47.54 sec\n",
      "Processed 41629 (100.0%) in 0.57 sec. BPR loss is 1.39E+01. Sample per second: 72357\n",
      "SLIM_BPR_Recommender: Epoch 248 of 465. Elapsed time 47.70 sec\n",
      "Processed 41629 (100.0%) in 0.73 sec. BPR loss is 1.39E+01. Sample per second: 56788\n",
      "SLIM_BPR_Recommender: Epoch 249 of 465. Elapsed time 47.86 sec\n",
      "Processed 41629 (100.0%) in 0.89 sec. BPR loss is 1.38E+01. Sample per second: 46603\n",
      "SLIM_BPR_Recommender: Epoch 250 of 465. Elapsed time 48.02 sec\n",
      "Processed 41629 (100.0%) in 1.05 sec. BPR loss is 1.39E+01. Sample per second: 39491\n",
      "SLIM_BPR_Recommender: Epoch 251 of 465. Elapsed time 48.18 sec\n",
      "Processed 41629 (100.0%) in 0.22 sec. BPR loss is 1.41E+01. Sample per second: 190670\n",
      "SLIM_BPR_Recommender: Epoch 252 of 465. Elapsed time 48.34 sec\n",
      "Processed 41629 (100.0%) in 0.41 sec. BPR loss is 1.40E+01. Sample per second: 100252\n",
      "SLIM_BPR_Recommender: Epoch 253 of 465. Elapsed time 48.54 sec\n",
      "Processed 41629 (100.0%) in 0.59 sec. BPR loss is 1.39E+01. Sample per second: 70935\n",
      "SLIM_BPR_Recommender: Epoch 254 of 465. Elapsed time 48.71 sec\n",
      "Processed 41629 (100.0%) in 0.77 sec. BPR loss is 1.38E+01. Sample per second: 54247\n",
      "SLIM_BPR_Recommender: Epoch 255 of 465. Elapsed time 48.89 sec\n",
      "Processed 41629 (100.0%) in 0.93 sec. BPR loss is 1.39E+01. Sample per second: 44782\n",
      "SLIM_BPR_Recommender: Epoch 256 of 465. Elapsed time 49.06 sec\n",
      "Processed 41629 (100.0%) in 1.09 sec. BPR loss is 1.41E+01. Sample per second: 38077\n",
      "SLIM_BPR_Recommender: Epoch 257 of 465. Elapsed time 49.22 sec\n",
      "Processed 41629 (100.0%) in 0.26 sec. BPR loss is 1.41E+01. Sample per second: 161974\n",
      "SLIM_BPR_Recommender: Epoch 258 of 465. Elapsed time 49.38 sec\n",
      "Processed 41629 (100.0%) in 0.43 sec. BPR loss is 1.39E+01. Sample per second: 97009\n",
      "SLIM_BPR_Recommender: Epoch 259 of 465. Elapsed time 49.56 sec\n",
      "Processed 41629 (100.0%) in 0.62 sec. BPR loss is 1.39E+01. Sample per second: 67404\n",
      "SLIM_BPR_Recommender: Epoch 260 of 465. Elapsed time 49.74 sec\n",
      "Processed 41629 (100.0%) in 0.82 sec. BPR loss is 1.42E+01. Sample per second: 50861\n",
      "SLIM_BPR_Recommender: Epoch 261 of 465. Elapsed time 49.95 sec\n",
      "Processed 41629 (100.0%) in 1.01 sec. BPR loss is 1.40E+01. Sample per second: 41300\n",
      "SLIM_BPR_Recommender: Epoch 262 of 465. Elapsed time 50.13 sec\n",
      "Processed 41629 (100.0%) in 0.17 sec. BPR loss is 1.40E+01. Sample per second: 242877\n",
      "SLIM_BPR_Recommender: Epoch 263 of 465. Elapsed time 50.30 sec\n",
      "Processed 41629 (100.0%) in 0.33 sec. BPR loss is 1.43E+01. Sample per second: 124405\n",
      "SLIM_BPR_Recommender: Epoch 264 of 465. Elapsed time 50.46 sec\n",
      "Processed 41629 (100.0%) in 0.50 sec. BPR loss is 1.41E+01. Sample per second: 83047\n",
      "SLIM_BPR_Recommender: Epoch 265 of 465. Elapsed time 50.63 sec\n",
      "Processed 41629 (100.0%) in 0.68 sec. BPR loss is 1.44E+01. Sample per second: 61103\n",
      "SLIM_BPR_Recommender: Epoch 266 of 465. Elapsed time 50.81 sec\n",
      "Processed 41629 (100.0%) in 0.85 sec. BPR loss is 1.41E+01. Sample per second: 49006\n",
      "SLIM_BPR_Recommender: Epoch 267 of 465. Elapsed time 50.98 sec\n",
      "Processed 41629 (100.0%) in 1.01 sec. BPR loss is 1.43E+01. Sample per second: 41149\n",
      "SLIM_BPR_Recommender: Epoch 268 of 465. Elapsed time 51.14 sec\n",
      "Processed 41629 (100.0%) in 0.19 sec. BPR loss is 1.44E+01. Sample per second: 222362\n",
      "SLIM_BPR_Recommender: Epoch 269 of 465. Elapsed time 51.31 sec\n",
      "Processed 41629 (100.0%) in 0.35 sec. BPR loss is 1.41E+01. Sample per second: 118805\n",
      "SLIM_BPR_Recommender: Epoch 270 of 465. Elapsed time 51.48 sec\n",
      "Processed 41629 (100.0%) in 0.52 sec. BPR loss is 1.45E+01. Sample per second: 80198\n",
      "SLIM_BPR_Recommender: Epoch 271 of 465. Elapsed time 51.65 sec\n",
      "Processed 41629 (100.0%) in 0.68 sec. BPR loss is 1.44E+01. Sample per second: 60532\n",
      "SLIM_BPR_Recommender: Epoch 272 of 465. Elapsed time 51.81 sec\n",
      "Processed 41629 (100.0%) in 0.87 sec. BPR loss is 1.45E+01. Sample per second: 47702\n",
      "SLIM_BPR_Recommender: Epoch 273 of 465. Elapsed time 52.00 sec\n",
      "Processed 41629 (100.0%) in 1.06 sec. BPR loss is 1.44E+01. Sample per second: 39246\n",
      "SLIM_BPR_Recommender: Epoch 274 of 465. Elapsed time 52.19 sec\n",
      "Processed 41629 (100.0%) in 0.26 sec. BPR loss is 1.44E+01. Sample per second: 160995\n",
      "SLIM_BPR_Recommender: Epoch 275 of 465. Elapsed time 52.39 sec\n",
      "Processed 41629 (100.0%) in 0.46 sec. BPR loss is 1.47E+01. Sample per second: 91097\n",
      "SLIM_BPR_Recommender: Epoch 276 of 465. Elapsed time 52.58 sec\n",
      "Processed 41629 (100.0%) in 0.63 sec. BPR loss is 1.45E+01. Sample per second: 65601\n",
      "SLIM_BPR_Recommender: Epoch 277 of 465. Elapsed time 52.76 sec\n",
      "Processed 41629 (100.0%) in 0.83 sec. BPR loss is 1.45E+01. Sample per second: 50156\n",
      "SLIM_BPR_Recommender: Epoch 278 of 465. Elapsed time 52.96 sec\n",
      "Processed 41629 (100.0%) in 1.04 sec. BPR loss is 1.45E+01. Sample per second: 40093\n",
      "SLIM_BPR_Recommender: Epoch 279 of 465. Elapsed time 53.17 sec\n",
      "Processed 41629 (100.0%) in 0.23 sec. BPR loss is 1.43E+01. Sample per second: 183177\n",
      "SLIM_BPR_Recommender: Epoch 280 of 465. Elapsed time 53.35 sec\n",
      "Processed 41629 (100.0%) in 0.43 sec. BPR loss is 1.44E+01. Sample per second: 97675\n",
      "SLIM_BPR_Recommender: Epoch 281 of 465. Elapsed time 53.55 sec\n",
      "Processed 41629 (100.0%) in 0.63 sec. BPR loss is 1.46E+01. Sample per second: 65813\n",
      "SLIM_BPR_Recommender: Epoch 282 of 465. Elapsed time 53.76 sec\n",
      "Processed 41629 (100.0%) in 0.83 sec. BPR loss is 1.48E+01. Sample per second: 50309\n",
      "SLIM_BPR_Recommender: Epoch 283 of 465. Elapsed time 53.95 sec\n",
      "Processed 41629 (100.0%) in 1.03 sec. BPR loss is 1.47E+01. Sample per second: 40270\n",
      "SLIM_BPR_Recommender: Epoch 284 of 465. Elapsed time 54.16 sec\n",
      "Processed 41629 (100.0%) in 0.22 sec. BPR loss is 1.50E+01. Sample per second: 188134\n",
      "SLIM_BPR_Recommender: Epoch 285 of 465. Elapsed time 54.35 sec\n",
      "Processed 41629 (100.0%) in 0.46 sec. BPR loss is 1.49E+01. Sample per second: 91024\n",
      "SLIM_BPR_Recommender: Epoch 286 of 465. Elapsed time 54.58 sec\n",
      "Processed 41629 (100.0%) in 0.66 sec. BPR loss is 1.47E+01. Sample per second: 63433\n",
      "SLIM_BPR_Recommender: Epoch 287 of 465. Elapsed time 54.78 sec\n",
      "Processed 41629 (100.0%) in 0.87 sec. BPR loss is 1.44E+01. Sample per second: 48066\n",
      "SLIM_BPR_Recommender: Epoch 288 of 465. Elapsed time 54.99 sec\n",
      "Processed 41629 (100.0%) in 1.09 sec. BPR loss is 1.47E+01. Sample per second: 38183\n",
      "SLIM_BPR_Recommender: Epoch 289 of 465. Elapsed time 55.22 sec\n",
      "Processed 41629 (100.0%) in 0.29 sec. BPR loss is 1.47E+01. Sample per second: 144953\n",
      "SLIM_BPR_Recommender: Epoch 290 of 465. Elapsed time 55.41 sec\n",
      "Processed 41629 (100.0%) in 0.51 sec. BPR loss is 1.48E+01. Sample per second: 82283\n",
      "SLIM_BPR_Recommender: Epoch 291 of 465. Elapsed time 55.63 sec\n",
      "Processed 41629 (100.0%) in 0.71 sec. BPR loss is 1.48E+01. Sample per second: 58569\n",
      "SLIM_BPR_Recommender: Epoch 292 of 465. Elapsed time 55.84 sec\n",
      "Processed 41629 (100.0%) in 0.91 sec. BPR loss is 1.47E+01. Sample per second: 45813\n",
      "SLIM_BPR_Recommender: Epoch 293 of 465. Elapsed time 56.04 sec\n",
      "Processed 41629 (100.0%) in 1.12 sec. BPR loss is 1.46E+01. Sample per second: 37187\n",
      "SLIM_BPR_Recommender: Epoch 294 of 465. Elapsed time 56.25 sec\n",
      "Processed 41629 (100.0%) in 0.33 sec. BPR loss is 1.49E+01. Sample per second: 126437\n",
      "SLIM_BPR_Recommender: Epoch 295 of 465. Elapsed time 56.46 sec\n",
      "Processed 41629 (100.0%) in 0.53 sec. BPR loss is 1.49E+01. Sample per second: 78970\n",
      "SLIM_BPR_Recommender: Epoch 296 of 465. Elapsed time 56.65 sec\n",
      "Processed 41629 (100.0%) in 0.74 sec. BPR loss is 1.47E+01. Sample per second: 56447\n",
      "SLIM_BPR_Recommender: Epoch 297 of 465. Elapsed time 56.87 sec\n",
      "Processed 41629 (100.0%) in 0.95 sec. BPR loss is 1.45E+01. Sample per second: 44014\n",
      "SLIM_BPR_Recommender: Epoch 298 of 465. Elapsed time 57.07 sec\n",
      "Processed 41629 (100.0%) in 1.14 sec. BPR loss is 1.47E+01. Sample per second: 36509\n",
      "SLIM_BPR_Recommender: Epoch 299 of 465. Elapsed time 57.27 sec\n",
      "Processed 41629 (100.0%) in 0.36 sec. BPR loss is 1.49E+01. Sample per second: 115965\n",
      "SLIM_BPR_Recommender: Epoch 300 of 465. Elapsed time 57.49 sec\n",
      "Processed 41629 (100.0%) in 0.55 sec. BPR loss is 1.50E+01. Sample per second: 75425\n",
      "SLIM_BPR_Recommender: Epoch 301 of 465. Elapsed time 57.68 sec\n",
      "Processed 41629 (100.0%) in 0.76 sec. BPR loss is 1.50E+01. Sample per second: 54975\n",
      "SLIM_BPR_Recommender: Epoch 302 of 465. Elapsed time 57.88 sec\n",
      "Processed 41629 (100.0%) in 0.95 sec. BPR loss is 1.49E+01. Sample per second: 43856\n",
      "SLIM_BPR_Recommender: Epoch 303 of 465. Elapsed time 58.08 sec\n",
      "Processed 41629 (100.0%) in 1.17 sec. BPR loss is 1.52E+01. Sample per second: 35582\n",
      "SLIM_BPR_Recommender: Epoch 304 of 465. Elapsed time 58.30 sec\n",
      "Processed 41629 (100.0%) in 0.35 sec. BPR loss is 1.49E+01. Sample per second: 118104\n",
      "SLIM_BPR_Recommender: Epoch 305 of 465. Elapsed time 58.48 sec\n",
      "Processed 41629 (100.0%) in 0.52 sec. BPR loss is 1.51E+01. Sample per second: 79357\n",
      "SLIM_BPR_Recommender: Epoch 306 of 465. Elapsed time 58.65 sec\n",
      "Processed 41629 (100.0%) in 0.70 sec. BPR loss is 1.49E+01. Sample per second: 59829\n",
      "SLIM_BPR_Recommender: Epoch 307 of 465. Elapsed time 58.82 sec\n",
      "Processed 41629 (100.0%) in 0.85 sec. BPR loss is 1.49E+01. Sample per second: 48886\n",
      "SLIM_BPR_Recommender: Epoch 308 of 465. Elapsed time 58.98 sec\n",
      "Processed 41629 (100.0%) in 1.03 sec. BPR loss is 1.54E+01. Sample per second: 40374\n",
      "SLIM_BPR_Recommender: Epoch 309 of 465. Elapsed time 59.16 sec\n",
      "Processed 41629 (100.0%) in 0.19 sec. BPR loss is 1.53E+01. Sample per second: 215141\n",
      "SLIM_BPR_Recommender: Epoch 310 of 465. Elapsed time 59.32 sec\n",
      "Processed 41629 (100.0%) in 0.36 sec. BPR loss is 1.53E+01. Sample per second: 116239\n",
      "SLIM_BPR_Recommender: Epoch 311 of 465. Elapsed time 59.48 sec\n",
      "Processed 41629 (100.0%) in 0.53 sec. BPR loss is 1.53E+01. Sample per second: 78071\n",
      "SLIM_BPR_Recommender: Epoch 312 of 465. Elapsed time 59.66 sec\n",
      "Processed 41629 (100.0%) in 0.71 sec. BPR loss is 1.54E+01. Sample per second: 58979\n",
      "SLIM_BPR_Recommender: Epoch 313 of 465. Elapsed time 59.83 sec\n",
      "Processed 41629 (100.0%) in 0.87 sec. BPR loss is 1.50E+01. Sample per second: 47931\n",
      "SLIM_BPR_Recommender: Epoch 314 of 465. Elapsed time 59.99 sec\n",
      "Processed 41629 (100.0%) in 1.03 sec. BPR loss is 1.53E+01. Sample per second: 40272\n",
      "SLIM_BPR_Recommender: Epoch 315 of 465. Elapsed time 1.00 min\n",
      "Processed 41629 (100.0%) in 0.20 sec. BPR loss is 1.52E+01. Sample per second: 211855\n",
      "SLIM_BPR_Recommender: Epoch 316 of 465. Elapsed time 1.01 min\n",
      "Processed 41629 (100.0%) in 0.36 sec. BPR loss is 1.53E+01. Sample per second: 115727\n",
      "SLIM_BPR_Recommender: Epoch 317 of 465. Elapsed time 1.01 min\n",
      "Processed 41629 (100.0%) in 0.53 sec. BPR loss is 1.53E+01. Sample per second: 78795\n",
      "SLIM_BPR_Recommender: Epoch 318 of 465. Elapsed time 1.01 min\n",
      "Processed 41629 (100.0%) in 0.69 sec. BPR loss is 1.54E+01. Sample per second: 60241\n",
      "SLIM_BPR_Recommender: Epoch 319 of 465. Elapsed time 1.01 min\n",
      "Processed 41629 (100.0%) in 0.86 sec. BPR loss is 1.52E+01. Sample per second: 48063\n",
      "SLIM_BPR_Recommender: Epoch 320 of 465. Elapsed time 1.02 min\n",
      "Processed 41629 (100.0%) in 1.04 sec. BPR loss is 1.51E+01. Sample per second: 40018\n",
      "SLIM_BPR_Recommender: Epoch 321 of 465. Elapsed time 1.02 min\n",
      "Processed 41629 (100.0%) in 0.22 sec. BPR loss is 1.52E+01. Sample per second: 186852\n",
      "SLIM_BPR_Recommender: Epoch 322 of 465. Elapsed time 1.02 min\n",
      "Processed 41629 (100.0%) in 0.39 sec. BPR loss is 1.51E+01. Sample per second: 105948\n",
      "SLIM_BPR_Recommender: Epoch 323 of 465. Elapsed time 1.03 min\n",
      "Processed 41629 (100.0%) in 0.57 sec. BPR loss is 1.56E+01. Sample per second: 73482\n",
      "SLIM_BPR_Recommender: Epoch 324 of 465. Elapsed time 1.03 min\n",
      "Processed 41629 (100.0%) in 0.74 sec. BPR loss is 1.55E+01. Sample per second: 56623\n",
      "SLIM_BPR_Recommender: Epoch 325 of 465. Elapsed time 1.03 min\n",
      "Processed 41629 (100.0%) in 0.90 sec. BPR loss is 1.52E+01. Sample per second: 46289\n",
      "SLIM_BPR_Recommender: Epoch 326 of 465. Elapsed time 1.03 min\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 1.55E+01. Sample per second: 38960\n",
      "SLIM_BPR_Recommender: Epoch 327 of 465. Elapsed time 1.04 min\n",
      "Processed 41629 (100.0%) in 0.23 sec. BPR loss is 1.55E+01. Sample per second: 182805\n",
      "SLIM_BPR_Recommender: Epoch 328 of 465. Elapsed time 1.04 min\n",
      "Processed 41629 (100.0%) in 0.38 sec. BPR loss is 1.54E+01. Sample per second: 108323\n",
      "SLIM_BPR_Recommender: Epoch 329 of 465. Elapsed time 1.04 min\n",
      "Processed 41629 (100.0%) in 0.55 sec. BPR loss is 1.55E+01. Sample per second: 75488\n",
      "SLIM_BPR_Recommender: Epoch 330 of 465. Elapsed time 1.04 min\n",
      "Processed 41629 (100.0%) in 0.73 sec. BPR loss is 1.55E+01. Sample per second: 57092\n",
      "SLIM_BPR_Recommender: Epoch 331 of 465. Elapsed time 1.05 min\n",
      "Processed 41629 (100.0%) in 0.89 sec. BPR loss is 1.54E+01. Sample per second: 46782\n",
      "SLIM_BPR_Recommender: Epoch 332 of 465. Elapsed time 1.05 min\n",
      "Processed 41629 (100.0%) in 1.12 sec. BPR loss is 1.57E+01. Sample per second: 37055\n",
      "SLIM_BPR_Recommender: Epoch 333 of 465. Elapsed time 1.05 min\n",
      "Processed 41629 (100.0%) in 0.53 sec. BPR loss is 1.57E+01. Sample per second: 77939\n",
      "SLIM_BPR_Recommender: Epoch 334 of 465. Elapsed time 1.06 min\n",
      "Processed 41629 (100.0%) in 0.75 sec. BPR loss is 1.57E+01. Sample per second: 55844\n",
      "SLIM_BPR_Recommender: Epoch 335 of 465. Elapsed time 1.06 min\n",
      "Processed 41629 (100.0%) in 0.94 sec. BPR loss is 1.58E+01. Sample per second: 44060\n",
      "SLIM_BPR_Recommender: Epoch 336 of 465. Elapsed time 1.07 min\n",
      "Processed 41629 (100.0%) in 1.14 sec. BPR loss is 1.56E+01. Sample per second: 36430\n",
      "SLIM_BPR_Recommender: Epoch 337 of 465. Elapsed time 1.07 min\n",
      "Processed 41629 (100.0%) in 0.34 sec. BPR loss is 1.55E+01. Sample per second: 123825\n",
      "SLIM_BPR_Recommender: Epoch 338 of 465. Elapsed time 1.07 min\n",
      "Processed 41629 (100.0%) in 0.55 sec. BPR loss is 1.56E+01. Sample per second: 75358\n",
      "SLIM_BPR_Recommender: Epoch 339 of 465. Elapsed time 1.08 min\n",
      "Processed 41629 (100.0%) in 0.76 sec. BPR loss is 1.58E+01. Sample per second: 54865\n",
      "SLIM_BPR_Recommender: Epoch 340 of 465. Elapsed time 1.08 min\n",
      "Processed 41629 (100.0%) in 0.94 sec. BPR loss is 1.57E+01. Sample per second: 44087\n",
      "SLIM_BPR_Recommender: Epoch 341 of 465. Elapsed time 1.08 min\n",
      "Processed 41629 (100.0%) in 1.15 sec. BPR loss is 1.57E+01. Sample per second: 36072\n",
      "SLIM_BPR_Recommender: Epoch 342 of 465. Elapsed time 1.09 min\n",
      "Processed 41629 (100.0%) in 0.36 sec. BPR loss is 1.59E+01. Sample per second: 115191\n",
      "SLIM_BPR_Recommender: Epoch 343 of 465. Elapsed time 1.09 min\n",
      "Processed 41629 (100.0%) in 0.57 sec. BPR loss is 1.58E+01. Sample per second: 72628\n",
      "SLIM_BPR_Recommender: Epoch 344 of 465. Elapsed time 1.10 min\n",
      "Processed 41629 (100.0%) in 0.81 sec. BPR loss is 1.56E+01. Sample per second: 51661\n",
      "SLIM_BPR_Recommender: Epoch 345 of 465. Elapsed time 1.10 min\n",
      "Processed 41629 (100.0%) in 1.01 sec. BPR loss is 1.57E+01. Sample per second: 41128\n",
      "SLIM_BPR_Recommender: Epoch 346 of 465. Elapsed time 1.10 min\n",
      "Processed 41629 (100.0%) in 0.23 sec. BPR loss is 1.57E+01. Sample per second: 181054\n",
      "SLIM_BPR_Recommender: Epoch 347 of 465. Elapsed time 1.11 min\n",
      "Processed 41629 (100.0%) in 0.44 sec. BPR loss is 1.59E+01. Sample per second: 95539\n",
      "SLIM_BPR_Recommender: Epoch 348 of 465. Elapsed time 1.11 min\n",
      "Processed 41629 (100.0%) in 0.65 sec. BPR loss is 1.57E+01. Sample per second: 63947\n",
      "SLIM_BPR_Recommender: Epoch 349 of 465. Elapsed time 1.11 min\n",
      "Processed 41629 (100.0%) in 0.86 sec. BPR loss is 1.59E+01. Sample per second: 48389\n",
      "SLIM_BPR_Recommender: Epoch 350 of 465. Elapsed time 1.12 min\n",
      "Processed 41629 (100.0%) in 1.08 sec. BPR loss is 1.55E+01. Sample per second: 38491\n",
      "SLIM_BPR_Recommender: Epoch 351 of 465. Elapsed time 1.12 min\n",
      "Processed 41629 (100.0%) in 0.28 sec. BPR loss is 1.57E+01. Sample per second: 147413\n",
      "SLIM_BPR_Recommender: Epoch 352 of 465. Elapsed time 1.12 min\n",
      "Processed 41629 (100.0%) in 0.50 sec. BPR loss is 1.58E+01. Sample per second: 83643\n",
      "SLIM_BPR_Recommender: Epoch 353 of 465. Elapsed time 1.13 min\n",
      "Processed 41629 (100.0%) in 0.69 sec. BPR loss is 1.58E+01. Sample per second: 60409\n",
      "SLIM_BPR_Recommender: Epoch 354 of 465. Elapsed time 1.13 min\n",
      "Processed 41629 (100.0%) in 0.89 sec. BPR loss is 1.60E+01. Sample per second: 46618\n",
      "SLIM_BPR_Recommender: Epoch 355 of 465. Elapsed time 1.13 min\n",
      "Processed 41629 (100.0%) in 1.09 sec. BPR loss is 1.58E+01. Sample per second: 38283\n",
      "SLIM_BPR_Recommender: Epoch 356 of 465. Elapsed time 1.14 min\n",
      "Processed 41629 (100.0%) in 0.27 sec. BPR loss is 1.61E+01. Sample per second: 153073\n",
      "SLIM_BPR_Recommender: Epoch 357 of 465. Elapsed time 1.14 min\n",
      "Processed 41629 (100.0%) in 0.46 sec. BPR loss is 1.62E+01. Sample per second: 89839\n",
      "SLIM_BPR_Recommender: Epoch 358 of 465. Elapsed time 1.14 min\n",
      "Processed 41629 (100.0%) in 0.70 sec. BPR loss is 1.60E+01. Sample per second: 59726\n",
      "SLIM_BPR_Recommender: Epoch 359 of 465. Elapsed time 1.15 min\n",
      "Processed 41629 (100.0%) in 0.91 sec. BPR loss is 1.59E+01. Sample per second: 45507\n",
      "SLIM_BPR_Recommender: Epoch 360 of 465. Elapsed time 1.15 min\n",
      "Processed 41629 (100.0%) in 1.11 sec. BPR loss is 1.61E+01. Sample per second: 37633\n",
      "SLIM_BPR_Recommender: Epoch 361 of 465. Elapsed time 1.15 min\n",
      "Processed 41629 (100.0%) in 0.29 sec. BPR loss is 1.62E+01. Sample per second: 144185\n",
      "SLIM_BPR_Recommender: Epoch 362 of 465. Elapsed time 1.16 min\n",
      "Processed 41629 (100.0%) in 0.49 sec. BPR loss is 1.59E+01. Sample per second: 84848\n",
      "SLIM_BPR_Recommender: Epoch 363 of 465. Elapsed time 1.16 min\n",
      "Processed 41629 (100.0%) in 0.69 sec. BPR loss is 1.60E+01. Sample per second: 60723\n",
      "SLIM_BPR_Recommender: Epoch 364 of 465. Elapsed time 1.16 min\n",
      "Processed 41629 (100.0%) in 0.94 sec. BPR loss is 1.60E+01. Sample per second: 44078\n",
      "SLIM_BPR_Recommender: Epoch 365 of 465. Elapsed time 1.17 min\n",
      "Processed 41629 (100.0%) in 1.18 sec. BPR loss is 1.61E+01. Sample per second: 35233\n",
      "SLIM_BPR_Recommender: Epoch 366 of 465. Elapsed time 1.17 min\n",
      "Processed 41629 (100.0%) in 0.36 sec. BPR loss is 1.61E+01. Sample per second: 114196\n",
      "SLIM_BPR_Recommender: Epoch 367 of 465. Elapsed time 1.17 min\n",
      "Processed 41629 (100.0%) in 0.54 sec. BPR loss is 1.62E+01. Sample per second: 76442\n",
      "SLIM_BPR_Recommender: Epoch 368 of 465. Elapsed time 1.18 min\n",
      "Processed 41629 (100.0%) in 0.73 sec. BPR loss is 1.63E+01. Sample per second: 57292\n",
      "SLIM_BPR_Recommender: Epoch 369 of 465. Elapsed time 1.18 min\n",
      "Processed 41629 (100.0%) in 0.90 sec. BPR loss is 1.60E+01. Sample per second: 46446\n",
      "SLIM_BPR_Recommender: Epoch 370 of 465. Elapsed time 1.18 min\n",
      "Processed 41629 (100.0%) in 1.06 sec. BPR loss is 1.61E+01. Sample per second: 39237\n",
      "SLIM_BPR_Recommender: Epoch 371 of 465. Elapsed time 1.19 min\n",
      "Processed 41629 (100.0%) in 0.23 sec. BPR loss is 1.60E+01. Sample per second: 180910\n",
      "SLIM_BPR_Recommender: Epoch 372 of 465. Elapsed time 1.19 min\n",
      "Processed 41629 (100.0%) in 0.40 sec. BPR loss is 1.66E+01. Sample per second: 104010\n",
      "SLIM_BPR_Recommender: Epoch 373 of 465. Elapsed time 1.19 min\n",
      "Processed 41629 (100.0%) in 0.57 sec. BPR loss is 1.64E+01. Sample per second: 73177\n",
      "SLIM_BPR_Recommender: Epoch 374 of 465. Elapsed time 1.19 min\n",
      "Processed 41629 (100.0%) in 0.74 sec. BPR loss is 1.60E+01. Sample per second: 56441\n",
      "SLIM_BPR_Recommender: Epoch 375 of 465. Elapsed time 1.20 min\n",
      "Processed 41629 (100.0%) in 0.91 sec. BPR loss is 1.60E+01. Sample per second: 45865\n",
      "SLIM_BPR_Recommender: Epoch 376 of 465. Elapsed time 1.20 min\n",
      "Processed 41629 (100.0%) in 1.07 sec. BPR loss is 1.63E+01. Sample per second: 39020\n",
      "SLIM_BPR_Recommender: Epoch 377 of 465. Elapsed time 1.20 min\n",
      "Processed 41629 (100.0%) in 0.23 sec. BPR loss is 1.62E+01. Sample per second: 177935\n",
      "SLIM_BPR_Recommender: Epoch 378 of 465. Elapsed time 1.21 min\n",
      "Processed 41629 (100.0%) in 0.39 sec. BPR loss is 1.63E+01. Sample per second: 105350\n",
      "SLIM_BPR_Recommender: Epoch 379 of 465. Elapsed time 1.21 min\n",
      "Processed 41629 (100.0%) in 0.55 sec. BPR loss is 1.64E+01. Sample per second: 75703\n",
      "SLIM_BPR_Recommender: Epoch 380 of 465. Elapsed time 1.21 min\n",
      "Processed 41629 (100.0%) in 0.72 sec. BPR loss is 1.64E+01. Sample per second: 58096\n",
      "SLIM_BPR_Recommender: Epoch 381 of 465. Elapsed time 1.21 min\n",
      "Processed 41629 (100.0%) in 0.87 sec. BPR loss is 1.66E+01. Sample per second: 47696\n",
      "SLIM_BPR_Recommender: Epoch 382 of 465. Elapsed time 1.22 min\n",
      "Processed 41629 (100.0%) in 1.05 sec. BPR loss is 1.63E+01. Sample per second: 39747\n",
      "SLIM_BPR_Recommender: Epoch 383 of 465. Elapsed time 1.22 min\n",
      "Processed 41629 (100.0%) in 0.21 sec. BPR loss is 1.63E+01. Sample per second: 196762\n",
      "SLIM_BPR_Recommender: Epoch 384 of 465. Elapsed time 1.22 min\n",
      "Processed 41629 (100.0%) in 0.37 sec. BPR loss is 1.66E+01. Sample per second: 111526\n",
      "SLIM_BPR_Recommender: Epoch 385 of 465. Elapsed time 1.23 min\n",
      "Processed 41629 (100.0%) in 0.53 sec. BPR loss is 1.64E+01. Sample per second: 77769\n",
      "SLIM_BPR_Recommender: Epoch 386 of 465. Elapsed time 1.23 min\n",
      "Processed 41629 (100.0%) in 0.70 sec. BPR loss is 1.65E+01. Sample per second: 59796\n",
      "SLIM_BPR_Recommender: Epoch 387 of 465. Elapsed time 1.23 min\n",
      "Processed 41629 (100.0%) in 0.86 sec. BPR loss is 1.64E+01. Sample per second: 48666\n",
      "SLIM_BPR_Recommender: Epoch 388 of 465. Elapsed time 1.23 min\n",
      "Processed 41629 (100.0%) in 1.03 sec. BPR loss is 1.63E+01. Sample per second: 40438\n",
      "SLIM_BPR_Recommender: Epoch 389 of 465. Elapsed time 1.24 min\n",
      "Processed 41629 (100.0%) in 0.18 sec. BPR loss is 1.64E+01. Sample per second: 225984\n",
      "SLIM_BPR_Recommender: Epoch 390 of 465. Elapsed time 1.24 min\n",
      "Processed 41629 (100.0%) in 0.34 sec. BPR loss is 1.63E+01. Sample per second: 121920\n",
      "SLIM_BPR_Recommender: Epoch 391 of 465. Elapsed time 1.24 min\n",
      "Processed 41629 (100.0%) in 0.52 sec. BPR loss is 1.63E+01. Sample per second: 79724\n",
      "SLIM_BPR_Recommender: Epoch 392 of 465. Elapsed time 1.24 min\n",
      "Processed 41629 (100.0%) in 0.68 sec. BPR loss is 1.65E+01. Sample per second: 60988\n",
      "SLIM_BPR_Recommender: Epoch 393 of 465. Elapsed time 1.25 min\n",
      "Processed 41629 (100.0%) in 0.85 sec. BPR loss is 1.63E+01. Sample per second: 49106\n",
      "SLIM_BPR_Recommender: Epoch 394 of 465. Elapsed time 1.25 min\n",
      "Processed 41629 (100.0%) in 1.01 sec. BPR loss is 1.64E+01. Sample per second: 41179\n",
      "SLIM_BPR_Recommender: Epoch 395 of 465. Elapsed time 1.25 min\n",
      "Processed 41629 (100.0%) in 0.18 sec. BPR loss is 1.67E+01. Sample per second: 232519\n",
      "SLIM_BPR_Recommender: Epoch 396 of 465. Elapsed time 1.26 min\n",
      "Processed 41629 (100.0%) in 0.35 sec. BPR loss is 1.65E+01. Sample per second: 119395\n",
      "SLIM_BPR_Recommender: Epoch 397 of 465. Elapsed time 1.26 min\n",
      "Processed 41629 (100.0%) in 0.54 sec. BPR loss is 1.67E+01. Sample per second: 76997\n",
      "SLIM_BPR_Recommender: Epoch 398 of 465. Elapsed time 1.26 min\n",
      "Processed 41629 (100.0%) in 0.75 sec. BPR loss is 1.66E+01. Sample per second: 55655\n",
      "SLIM_BPR_Recommender: Epoch 399 of 465. Elapsed time 1.26 min\n",
      "Processed 41629 (100.0%) in 0.96 sec. BPR loss is 1.67E+01. Sample per second: 43441\n",
      "SLIM_BPR_Recommender: Epoch 400 of 465. Elapsed time 1.27 min\n",
      "Processed 41629 (100.0%) in 1.18 sec. BPR loss is 1.66E+01. Sample per second: 35399\n",
      "SLIM_BPR_Recommender: Epoch 401 of 465. Elapsed time 1.27 min\n",
      "Processed 41629 (100.0%) in 0.39 sec. BPR loss is 1.66E+01. Sample per second: 107625\n",
      "SLIM_BPR_Recommender: Epoch 402 of 465. Elapsed time 1.28 min\n",
      "Processed 41629 (100.0%) in 0.59 sec. BPR loss is 1.65E+01. Sample per second: 70480\n",
      "SLIM_BPR_Recommender: Epoch 403 of 465. Elapsed time 1.28 min\n",
      "Processed 41629 (100.0%) in 0.81 sec. BPR loss is 1.66E+01. Sample per second: 51684\n",
      "SLIM_BPR_Recommender: Epoch 404 of 465. Elapsed time 1.28 min\n",
      "Processed 41629 (100.0%) in 1.01 sec. BPR loss is 1.69E+01. Sample per second: 41144\n",
      "SLIM_BPR_Recommender: Epoch 405 of 465. Elapsed time 1.29 min\n",
      "Processed 41629 (100.0%) in 0.22 sec. BPR loss is 1.65E+01. Sample per second: 188309\n",
      "SLIM_BPR_Recommender: Epoch 406 of 465. Elapsed time 1.29 min\n",
      "Processed 41629 (100.0%) in 0.43 sec. BPR loss is 1.70E+01. Sample per second: 97513\n",
      "SLIM_BPR_Recommender: Epoch 407 of 465. Elapsed time 1.29 min\n",
      "Processed 41629 (100.0%) in 0.61 sec. BPR loss is 1.67E+01. Sample per second: 67701\n",
      "SLIM_BPR_Recommender: Epoch 408 of 465. Elapsed time 1.30 min\n",
      "Processed 41629 (100.0%) in 0.81 sec. BPR loss is 1.69E+01. Sample per second: 51688\n",
      "SLIM_BPR_Recommender: Epoch 409 of 465. Elapsed time 1.30 min\n",
      "Processed 41629 (100.0%) in 1.00 sec. BPR loss is 1.69E+01. Sample per second: 41494\n",
      "SLIM_BPR_Recommender: Epoch 410 of 465. Elapsed time 1.30 min\n",
      "Processed 41629 (100.0%) in 0.19 sec. BPR loss is 1.69E+01. Sample per second: 223471\n",
      "SLIM_BPR_Recommender: Epoch 411 of 465. Elapsed time 1.31 min\n",
      "Processed 41629 (100.0%) in 0.37 sec. BPR loss is 1.67E+01. Sample per second: 111216\n",
      "SLIM_BPR_Recommender: Epoch 412 of 465. Elapsed time 1.31 min\n",
      "Processed 41629 (100.0%) in 0.57 sec. BPR loss is 1.70E+01. Sample per second: 73136\n",
      "SLIM_BPR_Recommender: Epoch 413 of 465. Elapsed time 1.31 min\n",
      "Processed 41629 (100.0%) in 0.78 sec. BPR loss is 1.69E+01. Sample per second: 53439\n",
      "SLIM_BPR_Recommender: Epoch 414 of 465. Elapsed time 1.32 min\n",
      "Processed 41629 (100.0%) in 1.01 sec. BPR loss is 1.66E+01. Sample per second: 41149\n",
      "SLIM_BPR_Recommender: Epoch 415 of 465. Elapsed time 1.32 min\n",
      "Processed 41629 (100.0%) in 0.21 sec. BPR loss is 1.70E+01. Sample per second: 197239\n",
      "SLIM_BPR_Recommender: Epoch 416 of 465. Elapsed time 1.32 min\n",
      "Processed 41629 (100.0%) in 0.42 sec. BPR loss is 1.69E+01. Sample per second: 99626\n",
      "SLIM_BPR_Recommender: Epoch 417 of 465. Elapsed time 1.33 min\n",
      "Processed 41629 (100.0%) in 0.62 sec. BPR loss is 1.71E+01. Sample per second: 66640\n",
      "SLIM_BPR_Recommender: Epoch 418 of 465. Elapsed time 1.33 min\n",
      "Processed 41629 (100.0%) in 0.83 sec. BPR loss is 1.70E+01. Sample per second: 50453\n",
      "SLIM_BPR_Recommender: Epoch 419 of 465. Elapsed time 1.33 min\n",
      "Processed 41629 (100.0%) in 1.02 sec. BPR loss is 1.68E+01. Sample per second: 40992\n",
      "SLIM_BPR_Recommender: Epoch 420 of 465. Elapsed time 1.34 min\n",
      "Processed 41629 (100.0%) in 0.23 sec. BPR loss is 1.71E+01. Sample per second: 182328\n",
      "SLIM_BPR_Recommender: Epoch 421 of 465. Elapsed time 1.34 min\n",
      "Processed 41629 (100.0%) in 0.44 sec. BPR loss is 1.72E+01. Sample per second: 94901\n",
      "SLIM_BPR_Recommender: Epoch 422 of 465. Elapsed time 1.34 min\n",
      "Processed 41629 (100.0%) in 0.66 sec. BPR loss is 1.71E+01. Sample per second: 63185\n",
      "SLIM_BPR_Recommender: Epoch 423 of 465. Elapsed time 1.35 min\n",
      "Processed 41629 (100.0%) in 0.87 sec. BPR loss is 1.71E+01. Sample per second: 47787\n",
      "SLIM_BPR_Recommender: Epoch 424 of 465. Elapsed time 1.35 min\n",
      "Processed 41629 (100.0%) in 1.09 sec. BPR loss is 1.69E+01. Sample per second: 38143\n",
      "SLIM_BPR_Recommender: Epoch 425 of 465. Elapsed time 1.35 min\n",
      "Processed 41629 (100.0%) in 0.30 sec. BPR loss is 1.70E+01. Sample per second: 138896\n",
      "SLIM_BPR_Recommender: Epoch 426 of 465. Elapsed time 1.36 min\n",
      "Processed 41629 (100.0%) in 0.50 sec. BPR loss is 1.69E+01. Sample per second: 83573\n",
      "SLIM_BPR_Recommender: Epoch 427 of 465. Elapsed time 1.36 min\n",
      "Processed 41629 (100.0%) in 0.69 sec. BPR loss is 1.72E+01. Sample per second: 60153\n",
      "SLIM_BPR_Recommender: Epoch 428 of 465. Elapsed time 1.36 min\n",
      "Processed 41629 (100.0%) in 0.90 sec. BPR loss is 1.69E+01. Sample per second: 46033\n",
      "SLIM_BPR_Recommender: Epoch 429 of 465. Elapsed time 1.37 min\n",
      "Processed 41629 (100.0%) in 1.10 sec. BPR loss is 1.71E+01. Sample per second: 37734\n",
      "SLIM_BPR_Recommender: Epoch 430 of 465. Elapsed time 1.37 min\n",
      "Processed 41629 (100.0%) in 0.30 sec. BPR loss is 1.72E+01. Sample per second: 139813\n",
      "SLIM_BPR_Recommender: Epoch 431 of 465. Elapsed time 1.37 min\n",
      "Processed 41629 (100.0%) in 0.46 sec. BPR loss is 1.70E+01. Sample per second: 90986\n",
      "SLIM_BPR_Recommender: Epoch 432 of 465. Elapsed time 1.38 min\n",
      "Processed 41629 (100.0%) in 0.62 sec. BPR loss is 1.72E+01. Sample per second: 66700\n",
      "SLIM_BPR_Recommender: Epoch 433 of 465. Elapsed time 1.38 min\n",
      "Processed 41629 (100.0%) in 0.79 sec. BPR loss is 1.73E+01. Sample per second: 52707\n",
      "SLIM_BPR_Recommender: Epoch 434 of 465. Elapsed time 1.38 min\n",
      "Processed 41629 (100.0%) in 0.95 sec. BPR loss is 1.73E+01. Sample per second: 43684\n",
      "SLIM_BPR_Recommender: Epoch 435 of 465. Elapsed time 1.38 min\n",
      "Processed 41629 (100.0%) in 1.11 sec. BPR loss is 1.71E+01. Sample per second: 37511\n",
      "SLIM_BPR_Recommender: Epoch 436 of 465. Elapsed time 1.39 min\n",
      "Processed 41629 (100.0%) in 0.28 sec. BPR loss is 1.72E+01. Sample per second: 148971\n",
      "SLIM_BPR_Recommender: Epoch 437 of 465. Elapsed time 1.39 min\n",
      "Processed 41629 (100.0%) in 0.45 sec. BPR loss is 1.73E+01. Sample per second: 93199\n",
      "SLIM_BPR_Recommender: Epoch 438 of 465. Elapsed time 1.39 min\n",
      "Processed 41629 (100.0%) in 0.61 sec. BPR loss is 1.74E+01. Sample per second: 68317\n",
      "SLIM_BPR_Recommender: Epoch 439 of 465. Elapsed time 1.40 min\n",
      "Processed 41629 (100.0%) in 0.78 sec. BPR loss is 1.73E+01. Sample per second: 53406\n",
      "SLIM_BPR_Recommender: Epoch 440 of 465. Elapsed time 1.40 min\n",
      "Processed 41629 (100.0%) in 0.97 sec. BPR loss is 1.72E+01. Sample per second: 42702\n",
      "SLIM_BPR_Recommender: Epoch 441 of 465. Elapsed time 1.40 min\n",
      "Processed 41629 (100.0%) in 1.16 sec. BPR loss is 1.74E+01. Sample per second: 35813\n",
      "SLIM_BPR_Recommender: Epoch 442 of 465. Elapsed time 1.40 min\n",
      "Processed 41629 (100.0%) in 0.33 sec. BPR loss is 1.74E+01. Sample per second: 127666\n",
      "SLIM_BPR_Recommender: Epoch 443 of 465. Elapsed time 1.41 min\n",
      "Processed 41629 (100.0%) in 0.48 sec. BPR loss is 1.71E+01. Sample per second: 86224\n",
      "SLIM_BPR_Recommender: Epoch 444 of 465. Elapsed time 1.41 min\n",
      "Processed 41629 (100.0%) in 0.64 sec. BPR loss is 1.74E+01. Sample per second: 65042\n",
      "SLIM_BPR_Recommender: Epoch 445 of 465. Elapsed time 1.41 min\n",
      "Processed 41629 (100.0%) in 0.81 sec. BPR loss is 1.73E+01. Sample per second: 51544\n",
      "SLIM_BPR_Recommender: Epoch 446 of 465. Elapsed time 1.42 min\n",
      "Processed 41629 (100.0%) in 0.97 sec. BPR loss is 1.72E+01. Sample per second: 42727\n",
      "SLIM_BPR_Recommender: Epoch 447 of 465. Elapsed time 1.42 min\n",
      "Processed 41629 (100.0%) in 1.14 sec. BPR loss is 1.78E+01. Sample per second: 36582\n",
      "SLIM_BPR_Recommender: Epoch 448 of 465. Elapsed time 1.42 min\n",
      "Processed 41629 (100.0%) in 0.31 sec. BPR loss is 1.76E+01. Sample per second: 132555\n",
      "SLIM_BPR_Recommender: Epoch 449 of 465. Elapsed time 1.42 min\n",
      "Processed 41629 (100.0%) in 0.48 sec. BPR loss is 1.72E+01. Sample per second: 86607\n",
      "SLIM_BPR_Recommender: Epoch 450 of 465. Elapsed time 1.43 min\n",
      "Processed 41629 (100.0%) in 0.65 sec. BPR loss is 1.73E+01. Sample per second: 64112\n",
      "SLIM_BPR_Recommender: Epoch 451 of 465. Elapsed time 1.43 min\n",
      "Processed 41629 (100.0%) in 0.81 sec. BPR loss is 1.75E+01. Sample per second: 51066\n",
      "SLIM_BPR_Recommender: Epoch 452 of 465. Elapsed time 1.43 min\n",
      "Processed 41629 (100.0%) in 0.98 sec. BPR loss is 1.74E+01. Sample per second: 42354\n",
      "SLIM_BPR_Recommender: Epoch 453 of 465. Elapsed time 1.44 min\n",
      "Processed 41629 (100.0%) in 1.15 sec. BPR loss is 1.73E+01. Sample per second: 36340\n",
      "SLIM_BPR_Recommender: Epoch 454 of 465. Elapsed time 1.44 min\n",
      "Processed 41629 (100.0%) in 0.32 sec. BPR loss is 1.76E+01. Sample per second: 131878\n",
      "SLIM_BPR_Recommender: Epoch 455 of 465. Elapsed time 1.44 min\n",
      "Processed 41629 (100.0%) in 0.48 sec. BPR loss is 1.74E+01. Sample per second: 87019\n",
      "SLIM_BPR_Recommender: Epoch 456 of 465. Elapsed time 1.44 min\n",
      "Processed 41629 (100.0%) in 0.65 sec. BPR loss is 1.77E+01. Sample per second: 64339\n",
      "SLIM_BPR_Recommender: Epoch 457 of 465. Elapsed time 1.45 min\n",
      "Processed 41629 (100.0%) in 0.81 sec. BPR loss is 1.75E+01. Sample per second: 51226\n",
      "SLIM_BPR_Recommender: Epoch 458 of 465. Elapsed time 1.45 min\n",
      "Processed 41629 (100.0%) in 0.98 sec. BPR loss is 1.75E+01. Sample per second: 42368\n",
      "SLIM_BPR_Recommender: Epoch 459 of 465. Elapsed time 1.45 min\n",
      "Processed 41629 (100.0%) in 1.17 sec. BPR loss is 1.77E+01. Sample per second: 35639\n",
      "SLIM_BPR_Recommender: Epoch 460 of 465. Elapsed time 1.45 min\n",
      "Processed 41629 (100.0%) in 0.35 sec. BPR loss is 1.76E+01. Sample per second: 117891\n",
      "SLIM_BPR_Recommender: Epoch 461 of 465. Elapsed time 1.46 min\n",
      "Processed 41629 (100.0%) in 0.54 sec. BPR loss is 1.78E+01. Sample per second: 76449\n",
      "SLIM_BPR_Recommender: Epoch 462 of 465. Elapsed time 1.46 min\n",
      "Processed 41629 (100.0%) in 0.73 sec. BPR loss is 1.74E+01. Sample per second: 57021\n",
      "SLIM_BPR_Recommender: Epoch 463 of 465. Elapsed time 1.46 min\n",
      "Processed 41629 (100.0%) in 0.95 sec. BPR loss is 1.78E+01. Sample per second: 43693\n",
      "SLIM_BPR_Recommender: Epoch 464 of 465. Elapsed time 1.47 min\n",
      "Processed 41629 (100.0%) in 1.16 sec. BPR loss is 1.77E+01. Sample per second: 35793\n",
      "SLIM_BPR_Recommender: Epoch 465 of 465. Elapsed time 1.47 min\n",
      "SLIM_BPR_Recommender: Terminating at epoch 465. Elapsed time 1.74 min\n",
      "Deallocating Cython objects\n"
     ]
    }
   ],
   "source": [
    "from Recommenders.SLIM.Cython.SLIM_BPR_Cython import SLIM_BPR_Cython\n",
    "recommender_SLIM_BPR_Cython = SLIM_BPR_Cython(URM_train)\n",
    "recommender_SLIM_BPR_Cython.fit(epochs=465, sgd_mode = \"sgd\", topK = 51, lambda_i = 0.0002099958148046903, lambda_j = 0.00020377687376060016, learning_rate = 0.02543768734456639)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Recommenders.GraphBased.RP3betaRecommender import RP3betaRecommender\n",
    "\n",
    "recommender_RP3beta = RP3betaRecommender(URM_train)\n",
    "recommender_RP3beta.fit(topK=167, alpha=1.0, beta=0.4520495673133021, implicit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP of the starting models\n",
      "EvaluatorHoldout: Processed 40693 (100.0%) in 19.96 sec. Users per second: 2038\n",
      "SLIM ElasticNet - MAP: 0.022279966836462446\n",
      "EvaluatorHoldout: Processed 40693 (100.0%) in 13.78 sec. Users per second: 2954\n",
      "RP3beta - MAP: 0.021232793635970547\n"
     ]
    }
   ],
   "source": [
    "print(\"MAP of the starting models\")\n",
    "\n",
    "result_df, _ = evaluator_test.evaluateRecommender(recommender_SLIMElasticNet)\n",
    "print(\"SLIM ElasticNet - MAP: {}\".format(result_df.loc[10][\"MAP\"]))\n",
    "\n",
    "result_df, _ = evaluator_test.evaluateRecommender(recommender_RP3beta)\n",
    "print(\"RP3beta - MAP: {}\".format(result_df.loc[10][\"MAP\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "from Recommenders.BaseRecommender import BaseRecommender\n",
    "\n",
    "class DifferentLossScoresHybridRecommender(BaseRecommender):\n",
    "    \"\"\" ScoresHybridRecommender\n",
    "    Hybrid of three predictions scores\n",
    "    R = R1*alpha + R2*beta + R3*(1-alpha-beta)\n",
    "\n",
    "    Class from Dacrema exercise modified by Antonio Ercolani\n",
    "    The original took as input 2 recommender\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    RECOMMENDER_NAME = \"DifferentLossScoresHybridRecommender\"\n",
    "\n",
    "\n",
    "    def __init__(self, URM_train, recommender_1, recommender_2, recommender_3):\n",
    "        super(DifferentLossScoresHybridRecommender, self).__init__(URM_train)\n",
    "\n",
    "        self.URM_train = sps.csr_matrix(URM_train)\n",
    "        self.recommender_1 = recommender_1\n",
    "        self.recommender_2 = recommender_2\n",
    "        self.recommender_3 = recommender_3\n",
    "\n",
    "\n",
    "\n",
    "    def fit(self, norm, alpha = 0.5, beta = 0.5):\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.norm = norm\n",
    "\n",
    "\n",
    "    def _compute_item_score(self, user_id_array, items_to_compute):\n",
    "\n",
    "        item_weights_1 = self.recommender_1._compute_item_score(user_id_array)\n",
    "        item_weights_2 = self.recommender_2._compute_item_score(user_id_array)\n",
    "        item_weights_3 = self.recommender_3._compute_item_score(user_id_array)\n",
    "\n",
    "        norm_item_weights_1 = LA.norm(item_weights_1, self.norm)\n",
    "        norm_item_weights_2 = LA.norm(item_weights_2, self.norm)\n",
    "        norm_item_weights_3 = LA.norm(item_weights_3, self.norm)\n",
    "\n",
    "\n",
    "        if norm_item_weights_1 == 0:\n",
    "            raise ValueError(\"Norm {} of item weights for recommender 1 is zero. Avoiding division by zero\".format(self.norm))\n",
    "\n",
    "        if norm_item_weights_2 == 0:\n",
    "            raise ValueError(\"Norm {} of item weights for recommender 2 is zero. Avoiding division by zero\".format(self.norm))\n",
    "\n",
    "        if norm_item_weights_3 == 0:\n",
    "            raise ValueError(\"Norm {} of item weights for recommender 3 is zero. Avoiding division by zero\".format(self.norm))\n",
    "\n",
    "        item_weights = item_weights_1 / norm_item_weights_1 * self.alpha + item_weights_2 / norm_item_weights_2 * self.beta + item_weights_3 / norm_item_weights_3 * (1-self.alpha-self.beta)\n",
    "\n",
    "        return item_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvaluatorHoldout: Processed 40060 (100.0%) in 25.33 sec. Users per second: 1582\n",
      "Norm: 1, Result: 0.01919768165212472\n",
      "EvaluatorHoldout: Processed 37000 (92.4%) in 5.07 min. Users per second: 122\n",
      "EvaluatorHoldout: Processed 40060 (100.0%) in 5.39 min. Users per second: 124\n",
      "Norm: 2, Result: 0.019198197743067625\n",
      "EvaluatorHoldout: Processed 40060 (100.0%) in 23.68 sec. Users per second: 1692\n",
      "Norm: inf, Result: 0.019207818232967737\n",
      "EvaluatorHoldout: Processed 40060 (100.0%) in 23.69 sec. Users per second: 1691\n",
      "Norm: -inf, Result: 0.01919809175126166\n"
     ]
    }
   ],
   "source": [
    "recommender_object = DifferentLossScoresHybridRecommender(URM_train, recommender_SLIMElasticNet, recommender_SLIM_BPR_Cython, recommender_RP3beta)\n",
    "\n",
    "best_model = {\n",
    "    \"MAP\" : 0,\n",
    "    \"alpha\" : 0,\n",
    "    \"beta\" : 0,\n",
    "    \"norm\" : 0\n",
    "}\n",
    "\n",
    "for norm in [1,2]:\n",
    "    for alpha in np.arange(0.0, 1.1, 0.1):\n",
    "        for beta in np.arange(0.0, 1.1, 0.1):\n",
    "\n",
    "            #truncate digits since np.arange sometimes doesn't\n",
    "            alpha = round(alpha,1)\n",
    "            beta = round(beta,1)\n",
    "\n",
    "\n",
    "            #discard cases in which the sum is greater than 1\n",
    "            if ( (alpha+beta) <= 1):\n",
    "                theta = round(1-alpha-beta,1)\n",
    "\n",
    "                print(\"----\")\n",
    "                recommender_object.fit(norm, alpha, beta)\n",
    "                result_df, _ = evaluator_validation.evaluateRecommender(recommender_object)\n",
    "                print(\"Norm: {}, Alpha: {}, Beta: {}, Theta: {}, Result: {}\".format(norm, alpha, beta, 1-alpha-beta, result_df.loc[10][\"MAP\"]))\n",
    "\n",
    "                if result_df.loc[10][\"MAP\"] > best_model[\"MAP\"]:\n",
    "                    best_model[\"MAP\"] = result_df.loc[10][\"MAP\"]\n",
    "                    best_model[\"alpha\"] = alpha\n",
    "                    best_model[\"beta\"] = beta\n",
    "                    best_model[\"norm\"] = norm\n",
    "\n",
    "                    print(\"*** New best model found! \")\n",
    "                    print(\"New best model has MAP: {} with alpha: {}, beta: {}, theta: {}, norm: {}\".format(best_model[\"MAP\"], best_model[\"alpha\"], best_model[\"beta\"],\n",
    "                                                                                                            1-best_model[\"alpha\"]-best_model[\"beta\"], best_model[\"norm\"]))\n",
    "\n",
    "print(\"----\")\n",
    "print(\"Best model has MAP: {} with alpha: {}, beta: {}, norm: {}\".format(best_model[\"MAP\"], best_model[\"alpha\"], best_model[\"beta\"], best_model[\"norm\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "delta_MAP_improvement = best_model[\"MAP\"] - 0.24831015633273928\n",
    "delta_MAP_improvement"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recommender_SLIMElasticNet = SLIMElasticNetRecommender(URM_train)\n",
    "recommender_SLIMElasticNet.fit(topK=405, l1_ratio=0.0010299956370568744, alpha=0.01)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recommender_SLIM_BPR_Cython = SLIM_BPR_Cython(URM_all)\n",
    "recommender_SLIM_BPR_Cython.fit(epochs=465, sgd_mode = \"sgd\", topK = 51, lambda_i = 0.0002099958148046903, lambda_j = 0.00020377687376060016, learning_rate = 0.02543768734456639)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from Recommenders.GraphBased.RP3betaRecommender import RP3betaRecommender\n",
    "\n",
    "recommender_RP3beta = RP3betaRecommender(URM_train)\n",
    "recommender_RP3beta.fit(topK=167, alpha=1.0, beta=0.4520495673133021, implicit=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recommender = DifferentLossScoresHybridRecommender(URM_all, recommender_SLIMElasticNet, recommender_RP3beta)\n",
    "recommender.fit(norm=1, alpha = 0.48, beta = 0.51)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users = pd.read_csv('Dataset/data_target_users_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = test_users['user_id']\n",
    "recommendations = []\n",
    "for user in user_id:\n",
    "    recommendations.append(recommender_object.recommend(user, cutoff=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(recommendations)):\n",
    "    recommendations[index]=np.array(recommendations[index])\n",
    "\n",
    "test_users['item_list']= recommendations\n",
    "test_users['item_list'] = pd.DataFrame([str(line).strip('[').strip(']').replace(\"'\",\"\") for line in test_users['item_list']])\n",
    "test_users.to_csv('Submissions\\Submission_10_SLIM_EN_rp3Beta_URM_Binary.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
